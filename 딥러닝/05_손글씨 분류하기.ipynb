{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "100ff930",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a33ff79",
   "metadata": {},
   "source": [
    "### 손글씨 데이터 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48a61d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "((X_train,y_train),(X_test,y_test)) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f77b8bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 손글씨 사진 데이터\n",
    "# 60000: 데이터의 수\n",
    "# 28 X 28 사진 데이터\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3b390a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 28, 28), (10000,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc35eb4",
   "metadata": {},
   "source": [
    "#### 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05762c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46a98328",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x25bb7907898>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAOUElEQVR4nO3dX4xUdZrG8ecFwT8MKiyt2zJEZtGYIRqBlLAJG0Qni38SBS5mAzGIxogXIDMJxEW5gAsvjO7MZBQzplEDbEYmhJEIiRkHCcYQE0OhTAuLLGpapkeEIkTH0QsU373ow6bFrl81VafqlP1+P0mnquup0+dNhYdTXae6fubuAjD0DSt6AACtQdmBICg7EARlB4Kg7EAQF7RyZ+PGjfOJEye2cpdAKD09PTp58qQNlDVUdjO7XdJvJQ2X9Ly7P5G6/8SJE1UulxvZJYCEUqlUNav7abyZDZf0rKQ7JE2WtNDMJtf78wA0VyO/s0+X9IG7f+TupyX9QdLcfMYCkLdGyj5e0l/7fd+b3fYdZrbEzMpmVq5UKg3sDkAjGin7QC8CfO+9t+7e5e4ldy91dHQ0sDsAjWik7L2SJvT7/seSPmlsHADN0kjZ90q61sx+YmYjJS2QtD2fsQDkre5Tb+7+jZktk/Sa+k69vejuB3ObDECuGjrP7u6vSno1p1kANBFvlwWCoOxAEJQdCIKyA0FQdiAIyg4EQdmBICg7EARlB4Kg7EAQlB0IgrIDQVB2IAjKDgRB2YEgKDsQBGUHgqDsQBCUHQiCsgNBUHYgCMoOBEHZgSAoOxAEZQeCoOxAEJQdCIKyA0FQdiCIhlZxRfs7c+ZMMv/888+buv9169ZVzb766qvktocPH07mzz77bDJfuXJl1Wzz5s3JbS+66KJkvmrVqmS+Zs2aZF6EhspuZj2SvpB0RtI37l7KYygA+cvjyH6Lu5/M4ecAaCJ+ZweCaLTsLunPZrbPzJYMdAczW2JmZTMrVyqVBncHoF6Nln2mu0+TdIekpWY269w7uHuXu5fcvdTR0dHg7gDUq6Gyu/sn2eUJSdskTc9jKAD5q7vsZjbKzEafvS5pjqQDeQ0GIF+NvBp/paRtZnb257zk7n/KZaoh5ujRo8n89OnTyfytt95K5nv27KmaffbZZ8ltt27dmsyLNGHChGT+8MMPJ/Nt27ZVzUaPHp3c9sYbb0zmN998czJvR3WX3d0/kpR+RAC0DU69AUFQdiAIyg4EQdmBICg7EAR/4pqDd999N5nfeuutybzZf2baroYPH57MH3/88WQ+atSoZH7PPfdUza666qrktmPGjEnm1113XTJvRxzZgSAoOxAEZQeCoOxAEJQdCIKyA0FQdiAIzrPn4Oqrr07m48aNS+btfJ59xowZybzW+ejdu3dXzUaOHJncdtGiRckc54cjOxAEZQeCoOxAEJQdCIKyA0FQdiAIyg4EwXn2HIwdOzaZP/XUU8l8x44dyXzq1KnJfPny5ck8ZcqUKcn89ddfT+a1/qb8wIHqSwk8/fTTyW2RL47sQBCUHQiCsgNBUHYgCMoOBEHZgSAoOxAE59lbYN68ecm81ufK11peuLu7u2r2/PPPJ7dduXJlMq91Hr2W66+/vmrW1dXV0M/G+al5ZDezF83shJkd6HfbWDPbaWZHssv0JxgAKNxgnsZvkHT7ObetkrTL3a+VtCv7HkAbq1l2d39T0qlzbp4raWN2faOkefmOBSBv9b5Ad6W7H5Ok7PKKanc0syVmVjazcqVSqXN3ABrV9Ffj3b3L3UvuXuro6Gj27gBUUW/Zj5tZpyRllyfyGwlAM9Rb9u2SFmfXF0t6JZ9xADRLzfPsZrZZ0mxJ48ysV9IaSU9I2mJmD0g6KunnzRxyqLv00ksb2v6yyy6re9ta5+EXLFiQzIcN431ZPxQ1y+7uC6tEP8t5FgBNxH/LQBCUHQiCsgNBUHYgCMoOBMGfuA4Ba9eurZrt27cvue0bb7yRzGt9lPScOXOSOdoHR3YgCMoOBEHZgSAoOxAEZQeCoOxAEJQdCILz7ENA6uOe169fn9x22rRpyfzBBx9M5rfccksyL5VKVbOlS5cmtzWzZI7zw5EdCIKyA0FQdiAIyg4EQdmBICg7EARlB4LgPPsQN2nSpGS+YcOGZH7//fcn802bNtWdf/nll8lt77333mTe2dmZzPFdHNmBICg7EARlB4Kg7EAQlB0IgrIDQVB2IAjOswc3f/78ZH7NNdck8xUrViTz1OfOP/roo8ltP/7442S+evXqZD5+/PhkHk3NI7uZvWhmJ8zsQL/b1prZ38xsf/Z1Z3PHBNCowTyN3yDp9gFu/427T8m+Xs13LAB5q1l2d39T0qkWzAKgiRp5gW6ZmXVnT/PHVLuTmS0xs7KZlSuVSgO7A9CIesv+O0mTJE2RdEzSr6rd0d273L3k7qWOjo46dwegUXWV3d2Pu/sZd/9W0npJ0/MdC0De6iq7mfX/28L5kg5Uuy+A9lDzPLuZbZY0W9I4M+uVtEbSbDObIskl9Uh6qHkjokg33HBDMt+yZUsy37FjR9XsvvvuS2773HPPJfMjR44k8507dybzaGqW3d0XDnDzC02YBUAT8XZZIAjKDgRB2YEgKDsQBGUHgjB3b9nOSqWSl8vllu0P7e3CCy9M5l9//XUyHzFiRDJ/7bXXqmazZ89ObvtDVSqVVC6XB1zrmiM7EARlB4Kg7EAQlB0IgrIDQVB2IAjKDgTBR0kjqbu7O5lv3bo1me/du7dqVus8ei2TJ09O5rNmzWro5w81HNmBICg7EARlB4Kg7EAQlB0IgrIDQVB2IAjOsw9xhw8fTubPPPNMMn/55ZeT+aeffnreMw3WBRek/3l2dnYm82HDOJb1x6MBBEHZgSAoOxAEZQeCoOxAEJQdCIKyA0Fwnv0HoNa57Jdeeqlqtm7duuS2PT099YyUi5tuuimZr169OpnffffdeY4z5NU8spvZBDPbbWaHzOygmf0iu32sme00syPZ5ZjmjwugXoN5Gv+NpBXu/lNJ/yppqZlNlrRK0i53v1bSrux7AG2qZtnd/Zi7v5Nd/0LSIUnjJc2VtDG720ZJ85o0I4AcnNcLdGY2UdJUSW9LutLdj0l9/yFIuqLKNkvMrGxm5Uql0uC4AOo16LKb2Y8k/VHSL93974Pdzt273L3k7qWOjo56ZgSQg0GV3cxGqK/ov3f3s38GddzMOrO8U9KJ5owIIA81T72ZmUl6QdIhd/91v2i7pMWSnsguX2nKhEPA8ePHk/nBgweT+bJly5L5+++/f94z5WXGjBnJ/JFHHqmazZ07N7ktf6Kar8GcZ58paZGk98xsf3bbY+or+RYze0DSUUk/b8qEAHJRs+zuvkfSgIu7S/pZvuMAaBaeJwFBUHYgCMoOBEHZgSAoOxAEf+I6SKdOnaqaPfTQQ8lt9+/fn8w//PDDekbKxcyZM5P5ihUrkvltt92WzC+++OLzngnNwZEdCIKyA0FQdiAIyg4EQdmBICg7EARlB4IIc5797bffTuZPPvlkMt+7d2/VrLe3t66Z8nLJJZdUzZYvX57cttbHNY8aNaqumdB+OLIDQVB2IAjKDgRB2YEgKDsQBGUHgqDsQBBhzrNv27atobwRkydPTuZ33XVXMh8+fHgyX7lyZdXs8ssvT26LODiyA0FQdiAIyg4EQdmBICg7EARlB4Kg7EAQ5u7pO5hNkLRJ0j9L+lZSl7v/1szWSnpQUiW762Pu/mrqZ5VKJS+Xyw0PDWBgpVJJ5XJ5wFWXB/Ommm8krXD3d8xstKR9ZrYzy37j7v+V16AAmmcw67Mfk3Qsu/6FmR2SNL7ZgwHI13n9zm5mEyVNlXT2M56WmVm3mb1oZmOqbLPEzMpmVq5UKgPdBUALDLrsZvYjSX+U9Et3/7uk30maJGmK+o78vxpoO3fvcveSu5c6OjoanxhAXQZVdjMbob6i/97dX5Ykdz/u7mfc/VtJ6yVNb96YABpVs+xmZpJekHTI3X/d7/bOfnebL+lA/uMByMtgXo2fKWmRpPfMbH9222OSFprZFEkuqUdSet1iAIUazKvxeyQNdN4ueU4dQHvhHXRAEJQdCIKyA0FQdiAIyg4EQdmBICg7EARlB4Kg7EAQlB0IgrIDQVB2IAjKDgRB2YEgan6UdK47M6tI+rjfTeMknWzZAOenXWdr17kkZqtXnrNd7e4Dfv5bS8v+vZ2bld29VNgACe06W7vOJTFbvVo1G0/jgSAoOxBE0WXvKnj/Ke06W7vOJTFbvVoyW6G/swNonaKP7ABahLIDQRRSdjO73cwOm9kHZraqiBmqMbMeM3vPzPabWaHrS2dr6J0wswP9bhtrZjvN7Eh2OeAaewXNttbM/pY9dvvN7M6CZptgZrvN7JCZHTSzX2S3F/rYJeZqyePW8t/ZzWy4pP+V9O+SeiXtlbTQ3f+npYNUYWY9kkruXvgbMMxslqR/SNrk7tdntz0p6ZS7P5H9RznG3f+zTWZbK+kfRS/jna1W1Nl/mXFJ8yTdpwIfu8Rc/6EWPG5FHNmnS/rA3T9y99OS/iBpbgFztD13f1PSqXNunitpY3Z9o/r+sbRcldnagrsfc/d3sutfSDq7zHihj11irpYoouzjJf213/e9aq/13l3Sn81sn5ktKXqYAVzp7sekvn88kq4oeJ5z1VzGu5XOWWa8bR67epY/b1QRZR9oKal2Ov83092nSbpD0tLs6SoGZ1DLeLfKAMuMt4V6lz9vVBFl75U0od/3P5b0SQFzDMjdP8kuT0japvZbivr42RV0s8sTBc/z/9ppGe+BlhlXGzx2RS5/XkTZ90q61sx+YmYjJS2QtL2AOb7HzEZlL5zIzEZJmqP2W4p6u6TF2fXFkl4pcJbvaJdlvKstM66CH7vClz9395Z/SbpTfa/IfyhpdREzVJnrXyT9Jfs6WPRskjar72nd1+p7RvSApH+StEvSkexybBvN9t+S3pPUrb5idRY027+p71fDbkn7s687i37sEnO15HHj7bJAELyDDgiCsgNBUHYgCMoOBEHZgSAoOxAEZQeC+D+ypTV9clByEAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# cmap = plt.cm.binary : 색상 > 흑백\n",
    "plt.imshow(X_train[0], cmap = plt.cm.binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23f7f027",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0 ~ 255까지의 숫자로 이루어져 있음\n",
    "# 0이 흰색\n",
    "# 255가 검은색\n",
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b75fd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기계는 0과 1사이의 숫자를 좋아함\n",
    "# 0 ~ 255까지의 숫자를 0 ~ 1까지로 만들어줌 \n",
    "# 전체 데이터를 255로 나눠줌\n",
    "X_train = X_train.astype('float32')/255\n",
    "X_test = X_test.astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61fa92f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 28 X 28의 2차원 데이터를 784의 1차원 데이터로 만들어줄 필요가 있음\n",
    "# input_dim에 집어넣기 위해서 !\n",
    "X_train = X_train.reshape((60000,28*28))\n",
    "X_test = X_test.reshape((10000,784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98803d3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97f6277d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.unique(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "043aca38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정답 데이터 원핫 인코딩\n",
    "import pandas as pd \n",
    "y_train = pd.get_dummies(y_train)\n",
    "y_test = pd.get_dummies(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1078c868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력층 개수: 784\n",
    "# 출력층 개수: 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c28232f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "seed = 100\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c6e47c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델설계\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "model = Sequential()\n",
    "# 입력층, 중간층의 활성화 함수: sigmoid\n",
    "#입력층\n",
    "model.add(Dense(units=1000, input_dim=784, activation='sigmoid' ))\n",
    "#중간층\n",
    "model.add(Dense(units= 500, activation='sigmoid'))\n",
    "model.add(Dense(units=250, activation = 'sigmoid'))\n",
    "model.add(Dense(units=125, activation = 'sigmoid'))\n",
    "model.add(Dense(units=60, activation = 'sigmoid'))\n",
    "model.add(Dense(units=30, activation = 'sigmoid'))\n",
    "model.add(Dense(units=15, activation ='sigmoid'))\n",
    "# 출력층의 활성화함수: softmax\n",
    "model.add(Dense(units=10,activation ='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9fa88d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 1000)              785000    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 500)               500500    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 250)               125250    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 125)               31375     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 60)                7560      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 30)                1830      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 15)                465       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                160       \n",
      "=================================================================\n",
      "Total params: 1,452,140\n",
      "Trainable params: 1,452,140\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0290e113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 학습 방법 설정\n",
    "# loss = categorical_crossentropy\n",
    "# optimizer = 'adam'\n",
    "# metrics = accracy\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "46b37011",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 784), (10000, 784), (60000, 10), (10000, 10))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "98e4ebce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 4s 70us/sample - loss: 1.7512 - accuracy: 0.3083 - val_loss: 1.2732 - val_accuracy: 0.4655\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 3s 53us/sample - loss: 1.0889 - accuracy: 0.5533 - val_loss: 0.8565 - val_accuracy: 0.8017\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 3s 53us/sample - loss: 0.5088 - accuracy: 0.8564 - val_loss: 0.3563 - val_accuracy: 0.9430\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 3s 52us/sample - loss: 0.2513 - accuracy: 0.9547 - val_loss: 0.1890 - val_accuracy: 0.9630\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 3s 53us/sample - loss: 0.1539 - accuracy: 0.9683 - val_loss: 0.1962 - val_accuracy: 0.9565\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 3s 53us/sample - loss: 0.1107 - accuracy: 0.9753 - val_loss: 0.1360 - val_accuracy: 0.9685\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 3s 53us/sample - loss: 0.0857 - accuracy: 0.9808 - val_loss: 0.1315 - val_accuracy: 0.9715\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.0693 - accuracy: 0.9840 - val_loss: 0.1138 - val_accuracy: 0.9745\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 3s 53us/sample - loss: 0.0575 - accuracy: 0.9868 - val_loss: 0.1134 - val_accuracy: 0.9757\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.0462 - accuracy: 0.9889 - val_loss: 0.1042 - val_accuracy: 0.9776\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 3s 53us/sample - loss: 0.0406 - accuracy: 0.9909 - val_loss: 0.1001 - val_accuracy: 0.9780\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 3s 53us/sample - loss: 0.0342 - accuracy: 0.9924 - val_loss: 0.1123 - val_accuracy: 0.9751\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 3s 53us/sample - loss: 0.0302 - accuracy: 0.9931 - val_loss: 0.0978 - val_accuracy: 0.9792\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 3s 53us/sample - loss: 0.0269 - accuracy: 0.9937 - val_loss: 0.1080 - val_accuracy: 0.9772\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 3s 53us/sample - loss: 0.0231 - accuracy: 0.9950 - val_loss: 0.1044 - val_accuracy: 0.9793\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.0195 - accuracy: 0.9955 - val_loss: 0.1074 - val_accuracy: 0.9797\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 3s 53us/sample - loss: 0.0206 - accuracy: 0.9954 - val_loss: 0.1124 - val_accuracy: 0.9801\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 3s 53us/sample - loss: 0.0174 - accuracy: 0.9962 - val_loss: 0.1133 - val_accuracy: 0.9797\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 3s 52us/sample - loss: 0.0160 - accuracy: 0.9962 - val_loss: 0.1157 - val_accuracy: 0.9804\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 3s 53us/sample - loss: 0.0151 - accuracy: 0.9966 - val_loss: 0.1186 - val_accuracy: 0.9784\n"
     ]
    }
   ],
   "source": [
    "# 모델 학습\n",
    "# epochs = 20 \n",
    "history1 = model.fit(X_train,y_train,epochs=20, validation_data=[X_test,y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "281235c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 37us/sample - loss: 0.1186 - accuracy: 0.9784\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.11864594642966986, 0.9784]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 평가\n",
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2a931390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 4s 60us/sample - loss: 0.2756 - accuracy: 0.9202 - val_loss: 0.1430 - val_accuracy: 0.9613\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 3s 53us/sample - loss: 0.1164 - accuracy: 0.9690 - val_loss: 0.1325 - val_accuracy: 0.9662\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 3s 53us/sample - loss: 0.0825 - accuracy: 0.9773 - val_loss: 0.1032 - val_accuracy: 0.9728\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 3s 52us/sample - loss: 0.0678 - accuracy: 0.9822 - val_loss: 0.1061 - val_accuracy: 0.9752\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 3s 52us/sample - loss: 0.0570 - accuracy: 0.9847 - val_loss: 0.0832 - val_accuracy: 0.9794\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 3s 53us/sample - loss: 0.0471 - accuracy: 0.9879 - val_loss: 0.0894 - val_accuracy: 0.9787\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 3s 53us/sample - loss: 0.0423 - accuracy: 0.9888 - val_loss: 0.0951 - val_accuracy: 0.9763\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 3s 52us/sample - loss: 0.0364 - accuracy: 0.9907 - val_loss: 0.1034 - val_accuracy: 0.9778\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 3s 53us/sample - loss: 0.0324 - accuracy: 0.9920 - val_loss: 0.0883 - val_accuracy: 0.9819\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 3s 52us/sample - loss: 0.0309 - accuracy: 0.9924 - val_loss: 0.0909 - val_accuracy: 0.9804\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 3s 52us/sample - loss: 0.0287 - accuracy: 0.9923 - val_loss: 0.0949 - val_accuracy: 0.9789\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 3s 52us/sample - loss: 0.0293 - accuracy: 0.9932 - val_loss: 0.0962 - val_accuracy: 0.9787\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 3s 53us/sample - loss: 0.0237 - accuracy: 0.9942 - val_loss: 0.1089 - val_accuracy: 0.9800\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 3s 53us/sample - loss: 0.0232 - accuracy: 0.9950 - val_loss: 0.0994 - val_accuracy: 0.9810\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 3s 53us/sample - loss: 0.0222 - accuracy: 0.9949 - val_loss: 0.1309 - val_accuracy: 0.9826\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 3s 53us/sample - loss: 0.0212 - accuracy: 0.9948 - val_loss: 0.0947 - val_accuracy: 0.9833\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.0162 - accuracy: 0.9963 - val_loss: 0.1063 - val_accuracy: 0.9822\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 3s 53us/sample - loss: 0.0164 - accuracy: 0.9961 - val_loss: 0.0964 - val_accuracy: 0.9812\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 3s 53us/sample - loss: 0.0187 - accuracy: 0.9953 - val_loss: 0.1320 - val_accuracy: 0.9827\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.0186 - accuracy: 0.9958 - val_loss: 0.0983 - val_accuracy: 0.9812\n"
     ]
    }
   ],
   "source": [
    "# 모든 조건은 동일 \n",
    "# model2라는 딥러닝 모델 설계\n",
    "# 입력층과 중간층의 활성화함수 sigmoid > relu\n",
    "# history2 = model2.fit()\n",
    "model2 = Sequential()\n",
    "# 입력층, 중간층의 활성화 함수: relu\n",
    "#입력층\n",
    "model2.add(Dense(units=1000, input_dim=784, activation='relu' ))\n",
    "#중간층\n",
    "model2.add(Dense(units= 500, activation='relu'))\n",
    "model2.add(Dense(units=250, activation = 'relu'))\n",
    "model2.add(Dense(units=125, activation = 'relu'))\n",
    "model2.add(Dense(units=60, activation = 'relu'))\n",
    "model2.add(Dense(units=30, activation = 'relu'))\n",
    "model2.add(Dense(units=15, activation ='relu'))\n",
    "# 출력층의 활성화함수: softmax\n",
    "model2.add(Dense(units=10,activation ='softmax'))\n",
    "\n",
    "model2.compile(loss='categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics = ['accuracy'])\n",
    "\n",
    "history2 = model2.fit(X_train,y_train,epochs=20, validation_data=[X_test,y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d806f606",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model1 > 입력층, 중간층 활성화함수: sigmoid >history1\n",
    "#model2 > 입력층, 중간층 활성화함수: relu>history2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1b8de841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "plt.plot(range(20),history1.history['accuracy'],label='model1')\n",
    "plt.plot(range(20),history2.history['accuracy'],label='model2')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9fa22540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.751210428237915,\n",
       " 1.0889288537661235,\n",
       " 0.5087685074051221,\n",
       " 0.2512601806998253,\n",
       " 0.1539233210494121,\n",
       " 0.11074703276554744,\n",
       " 0.08568106169700622,\n",
       " 0.06928911971524358,\n",
       " 0.05746918261696895,\n",
       " 0.046185391195863484,\n",
       " 0.040626416210457685,\n",
       " 0.034157935567076005,\n",
       " 0.03021530294070641,\n",
       " 0.02691468236471216,\n",
       " 0.023126897630654276,\n",
       " 0.01946408672997107,\n",
       " 0.020649619556342563,\n",
       " 0.017397870438235503,\n",
       " 0.015980162306626636,\n",
       " 0.015081549642731746]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model1에서 epochs를 돌린 결과가 들어있음\n",
    "# history라는 함수를 통해서 accuracy\n",
    "history1.history['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d07f4b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# jpg > 컬러사진\n",
    "# gif > 흑백사진"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780a43d4",
   "metadata": {},
   "source": [
    "직접 그린 그림 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0218c535",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image as pimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9259b80d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x25daa0c2da0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAL00lEQVR4nO3dT6gd5R3G8eep1Y26SJqjBJXGShaNQqMOoWARi1Q0m+giYhaSgnCzUFBwUbELzU5KVbookmsNpsUqCSpmEVpDEMSNeK6kmtvQaiXVaEhOcKGubPTXxZ2013j+eWbOzEl+3w8c5px5z73vj+E+d86Zd2ZeR4QAnPu+13YBAJpB2IEkCDuQBGEHkiDsQBLfb7KzVatWxZo1a5rsEkjlyJEjOnnypPu1VQq77Vsl/U7SeZL+EBGPDXv/mjVr1O12q3QJYIiiKAa2Tfwx3vZ5kn4v6TZJ6yRtsb1u0t8HYLqqfGffIOn9iPggIr6U9IKkTfWUBaBuVcJ+maSPlr0+Wq77Bttztru2u71er0J3AKqoEvZ+BwG+de5tRMxHRBERRafTqdAdgCqqhP2opCuWvb5c0ifVygEwLVXC/paktbavtH2BpLsk7a2nLAB1m3joLSJO2b5P0l+1NPS2MyIWa6sMQK0qjbNHxD5J+2qqBcAUcboskARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0k0OmXzLJvfMz+8ffvg9oXFhbrLOWtcr+uHts/tnhvctnlwG+rHnh1IgrADSRB2IAnCDiRB2IEkCDuQBGEHknBENNZZURTR7XYb62+5hT3Dx8KLO4uGKsFpTf7tZVEUhbrdrvu1VTqpxvYRSZ9L+krSqYggMcCMquMMup9HxMkafg+AKeI7O5BE1bCHpFdtL9jue6Kz7TnbXdvdXq9XsTsAk6oa9hsi4jpJt0m61/aNZ74hIuYjooiIotPpVOwOwKQqhT0iPimXJyS9LGlDHUUBqN/EYbd9oe2LTz+XdIukQ3UVBqBeVY7GXyrpZdunf8+fI+IvtVQ1BcV2RgWR28Rhj4gPJP2kxloATBFDb0AShB1IgrADSRB2IAnCDiSR5lbSOzbvGNq+bXHbxL971C2Rd+we3nebuPQ3D/bsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5BEmltJoz9f0/euw/+3OL2+uZV0/YbdSpo9O5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kkeZ69lk28pryUbfBnuJYeFWjrvVHc9izA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EASjLOPadhY+Nk8Dl7V2XzP/GxG7tlt77R9wvahZetW2t5v+71yuWK6ZQKoapyP8c9KuvWMdQ9JOhARayUdKF8DmGEjwx4Rr0v69IzVmyTtKp/vknR7vWUBqNukB+gujYhjklQuLxn0Rttztru2u71eb8LuAFQ19aPxETEfEUVEFJ1OZ9rdARhg0rAft71aksrlifpKAjANk4Z9r6St5fOtkl6ppxwA0zJynN3285JukrTK9lFJj0h6TNJu2/dI+lDS5mkWOQuGjqWfw+Po1199/dB2xtHPHiPDHhFbBjTdXHMtAKaI02WBJAg7kARhB5Ig7EAShB1Igktcx7Rj8+Ahpm2L2xqspFkLi8Nvcz2/Z35oO7eSnh3s2YEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCUdEY50VRRHdbrex/s4V89uHj2Vve3R2x/mb/PuCVBSFut2u+7WxZweSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJBhnP8e1PUbPOHuzGGcHQNiBLAg7kARhB5Ig7EAShB1IgrADSTDOnpzdd0i2NoyzN6vSOLvtnbZP2D60bN2jtj+2fbB8bKyzYAD1G+dj/LOSbu2z/smIWF8+9tVbFoC6jQx7RLwu6dMGagEwRVUO0N1n+53yY/6KQW+yPWe7a7vb6/UqdAegiknD/pSkqyStl3RM0uOD3hgR8xFRRETR6XQm7A5AVROFPSKOR8RXEfG1pKclbai3LAB1myjstlcve3mHpEOD3gtgNoycn93285JukrTK9lFJj0i6yfZ6SSHpiKTZvXE5AEljhD0itvRZ/cwUagEwRZwuCyRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEiOvestiYc/C0PZt2wdfxTv3yNzQn53bPLy9qoW/D669uLqYat84e7BnB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkmLK55GtGTF282Ewd5xqmbG5WpSmbAZwbCDuQBGEHkiDsQBKEHUiCsANJEHYgCa5nL82tG37N+fzifEOVnF2mfa0+6jNyz277Ctuv2T5se9H2/eX6lbb3236vXK6YfrkAJjXOx/hTkh6MiB9L+qmke22vk/SQpAMRsVbSgfI1gBk1MuwRcSwi3i6ffy7psKTLJG2StKt82y5Jt0+pRgA1+E4H6GyvkXStpDclXRoRx6SlfwiSLhnwM3O2u7a7vV6vYrkAJjV22G1fJOlFSQ9ExGfj/lxEzEdEERFFp9OZpEYANRgr7LbP11LQn4uIl8rVx22vLttXSzoxnRIB1GHk0JttS3pG0uGIeGJZ015JWyU9Vi5fmUqFDdmxe8fwN9w5uGl+z9k7LDdq6GzkdsFZY5xx9hsk3S3pXdsHy3UPaynku23fI+lDSZunUiGAWowMe0S8IWnQnR1urrccANPC6bJAEoQdSIKwA0kQdiAJwg4kwSWuYxo23rxDjEVj9rFnB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJEaG3fYVtl+zfdj2ou37y/WP2v7Y9sHysXH65QKY1DiTRJyS9GBEvG37YkkLtveXbU9GxG+nVx6AuowzP/sxScfK55/bPizpsmkXBqBe3+k7u+01kq6V9Ga56j7b79jeaXvFgJ+Zs9213e31etWqBTCxscNu+yJJL0p6ICI+k/SUpKskrdfSnv/xfj8XEfMRUURE0el0qlcMYCJjhd32+VoK+nMR8ZIkRcTxiPgqIr6W9LSkDdMrE0BV4xyNt6RnJB2OiCeWrV+97G13SDpUf3kA6jLO0fgbJN0t6V3bB8t1D0vaYnu9pJB0RNK2KdQHoCbjHI1/Q5L7NO2rvxwA08IZdEAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQcEc11Zvck/XvZqlWSTjZWwHczq7XNal0StU2qztp+GBF97//WaNi/1bndjYiitQKGmNXaZrUuidom1VRtfIwHkiDsQBJth32+5f6HmdXaZrUuidom1UhtrX5nB9CctvfsABpC2IEkWgm77Vtt/8P2+7YfaqOGQWwfsf1uOQ11t+Vadto+YfvQsnUrbe+3/V657DvHXku1zcQ03kOmGW9127U9/Xnj39ltnyfpn5J+IemopLckbYmIvzdayAC2j0gqIqL1EzBs3yjpC0l/jIhrynW/kfRpRDxW/qNcERG/mpHaHpX0RdvTeJezFa1ePs24pNsl/VItbrshdd2pBrZbG3v2DZLej4gPIuJLSS9I2tRCHTMvIl6X9OkZqzdJ2lU+36WlP5bGDahtJkTEsYh4u3z+uaTT04y3uu2G1NWINsJ+maSPlr0+qtma7z0kvWp7wfZc28X0cWlEHJOW/ngkXdJyPWcaOY13k86YZnxmtt0k059X1UbY+00lNUvjfzdExHWSbpN0b/lxFeMZaxrvpvSZZnwmTDr9eVVthP2opCuWvb5c0ict1NFXRHxSLk9IelmzNxX18dMz6JbLEy3X8z+zNI13v2nGNQPbrs3pz9sI+1uS1tq+0vYFku6StLeFOr7F9oXlgRPZvlDSLZq9qaj3StpaPt8q6ZUWa/mGWZnGe9A042p527U+/XlENP6QtFFLR+T/JenXbdQwoK4fSfpb+VhsuzZJz2vpY91/tPSJ6B5JP5B0QNJ75XLlDNX2J0nvSnpHS8Fa3VJtP9PSV8N3JB0sHxvb3nZD6mpku3G6LJAEZ9ABSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBL/BWZq38ocLEOOAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_num = pimg.open('num3.gif')\n",
    "plt.imshow(img_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c2da584c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAMAAABF0y+mAAADAFBMVEUAAAAAADMAAGYAAJkAAMwAAP8AKwAAKzMAK2YAK5kAK8wAK/8AVQAAVTMAVWYAVZkAVcwAVf8AgAAAgDMAgGYAgJkAgMwAgP8AqgAAqjMAqmYAqpkAqswAqv8A1QAA1TMA1WYA1ZkA1cwA1f8A/wAA/zMA/2YA/5kA/8wA//8zAAAzADMzAGYzAJkzAMwzAP8zKwAzKzMzK2YzK5kzK8wzK/8zVQAzVTMzVWYzVZkzVcwzVf8zgAAzgDMzgGYzgJkzgMwzgP8zqgAzqjMzqmYzqpkzqswzqv8z1QAz1TMz1WYz1Zkz1cwz1f8z/wAz/zMz/2Yz/5kz/8wz//9mAABmADNmAGZmAJlmAMxmAP9mKwBmKzNmK2ZmK5lmK8xmK/9mVQBmVTNmVWZmVZlmVcxmVf9mgABmgDNmgGZmgJlmgMxmgP9mqgBmqjNmqmZmqplmqsxmqv9m1QBm1TNm1WZm1Zlm1cxm1f9m/wBm/zNm/2Zm/5lm/8xm//+ZAACZADOZAGaZAJmZAMyZAP+ZKwCZKzOZK2aZK5mZK8yZK/+ZVQCZVTOZVWaZVZmZVcyZVf+ZgACZgDOZgGaZgJmZgMyZgP+ZqgCZqjOZqmaZqpmZqsyZqv+Z1QCZ1TOZ1WaZ1ZmZ1cyZ1f+Z/wCZ/zOZ/2aZ/5mZ/8yZ///MAADMADPMAGbMAJnMAMzMAP/MKwDMKzPMK2bMK5nMK8zMK//MVQDMVTPMVWbMVZnMVczMVf/MgADMgDPMgGbMgJnMgMzMgP/MqgDMqjPMqmbMqpnMqszMqv/M1QDM1TPM1WbM1ZnM1czM1f/M/wDM/zPM/2bM/5nM/8zM////AAD/ADP/AGb/AJn/AMz/AP//KwD/KzP/K2b/K5n/K8z/K///VQD/VTP/VWb/VZn/Vcz/Vf//gAD/gDP/gGb/gJn/gMz/gP//qgD/qjP/qmb/qpn/qsz/qv//1QD/1TP/1Wb/1Zn/1cz/1f///wD//zP//2b//5n//8z///8AAAAAAAAAAAAAAADZ9vIoAAAA/XRSTlP///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////8A9k80AwAAAGpJREFUeJy10rERwCAIBVAql0nFSqyUyn2oshJNziMYTsFKf/s8/HKCLAInsSJ8ueqIDC4jlhXeACQ2Ii1UMmQdTjOyXevN0AyDd7ZKmhrgfyBB5RRlMzK2lk9cyG1+RuoWbYgCOvzBtuML2EyAfcHoTIAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.GifImagePlugin.GifImageFile image mode=P size=28x28 at 0x25B93903A58>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 28*28 2차원 데이터 > 784의 1차원 데이터로 변환\n",
    "# 0 ~ 255사이의 픽셀값 > 0 ~1사이의 픽셀값-\n",
    "img_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bf5a3018",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
       "        251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
       "        251, 251],\n",
       "       [251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
       "        251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
       "        251, 251],\n",
       "       [251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
       "        251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
       "        251, 251],\n",
       "       [251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
       "        251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
       "        251, 251],\n",
       "       [251, 251, 251, 251, 251, 153,  49,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  43, 153, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
       "        251, 251],\n",
       "       [251, 251, 251, 251, 196,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
       "        251, 251],\n",
       "       [251, 251, 251, 251,   6,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
       "        251, 251],\n",
       "       [251, 251, 251, 251, 147,   0,   0,  98, 251, 251, 251, 251, 251,\n",
       "        196,   0,   0,   0, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
       "        251, 251],\n",
       "       [251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
       "          6,   0,   0,   0, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
       "        251, 251],\n",
       "       [251, 251, 251, 251, 251, 251, 251, 251, 251, 196,   6,   0,   0,\n",
       "          0,   0,   0,  98, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
       "        251, 251],\n",
       "       [251, 251, 251, 251, 251, 251, 196,   6,   0,   0,   0,   0,   0,\n",
       "          0,   0,  98, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
       "        251, 251],\n",
       "       [251, 251, 251, 251, 251, 251,   6,   0,   0,   0,   0,   0,   0,\n",
       "          0,  49, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
       "        251, 251],\n",
       "       [251, 251, 251, 251, 251, 251, 147,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0, 153, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
       "        251, 251],\n",
       "       [251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 147,   0,   0,\n",
       "          0,   0,   0, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
       "        251, 251],\n",
       "       [251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 147,\n",
       "          0,   0,   0, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
       "        251, 251],\n",
       "       [251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
       "          0,   0,   0, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
       "        251, 251],\n",
       "       [251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
       "          0,   0,   0, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
       "        251, 251],\n",
       "       [251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
       "          0,   0,   0, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
       "        251, 251],\n",
       "       [251, 251, 251, 251, 251, 196,  49, 153, 251, 251, 251, 202,   0,\n",
       "          0,   0,   0, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
       "        251, 251],\n",
       "       [251, 251, 251, 251, 251,   6,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
       "        251, 251],\n",
       "       [251, 251, 251, 251, 251,  98,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  98, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
       "        251, 251],\n",
       "       [251, 251, 251, 251, 251, 251,  98,   0,   0,   0,   0,   0,   0,\n",
       "         98, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
       "        251, 251],\n",
       "       [251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
       "        251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
       "        251, 251],\n",
       "       [251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
       "        251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
       "        251, 251],\n",
       "       [251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
       "        251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
       "        251, 251],\n",
       "       [251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
       "        251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
       "        251, 251],\n",
       "       [251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
       "        251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
       "        251, 251],\n",
       "       [251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
       "        251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
       "        251, 251]], dtype=uint8)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num=np.array(img_num)\n",
    "num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "674ea43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기존에는 흰색 > 0 검은색>255\n",
    "# 지금은 흰색이 > 255 검은색 >0 \n",
    "num = 255 - num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "db09deb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1차원 데이터로 변환\n",
    "num = num.reshape(1,784)\n",
    "num = num.astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bccc44b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0, 99,  0,  0,  0,  0,  0,  0]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model2.predict(num)*100).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "444723ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3], dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.predict_classes(num)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca963104",
   "metadata": {},
   "source": [
    "#### 모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e71d8c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.save('./model/model_handnum1.h5') #model폴더/파일이름.파일형식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f1e21f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 불러오기\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model3 = load_model('./model/model_handnum1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f8b52f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 2s 32us/sample - loss: 0.0201 - accuracy: 0.9947\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.020145516184974257, 0.99473333]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.evaluate(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2c75a26a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.0010 - accuracy: 0.9997\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.001041066051255196, 0.99965]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_youngsun=load_model('./model/youngsun.h5')\n",
    "model_youngsun.evaluate(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "050b8711",
   "metadata": {},
   "outputs": [],
   "source": [
    "#딥러닝에서 교차검증\n",
    "from sklearn.model_selection import KFold, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ec2987f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deep_model():\n",
    "    model2 = Sequential()\n",
    "# 입력층, 중간층의 활성화 함수: relu\n",
    "#입력층\n",
    "    model2.add(Dense(units=1000, input_dim=784, activation='relu' ))\n",
    "#중간층\n",
    "    model2.add(Dense(units= 500, activation='relu'))\n",
    "    model2.add(Dense(units=250, activation = 'relu'))\n",
    "    model2.add(Dense(units=125, activation = 'relu'))\n",
    "    model2.add(Dense(units=60, activation = 'relu'))\n",
    "    model2.add(Dense(units=30, activation = 'relu'))\n",
    "    model2.add(Dense(units=15, activation ='relu'))\n",
    "# 출력층의 활성화함수: softmax\n",
    "    model2.add(Dense(units=10,activation ='softmax'))\n",
    "\n",
    "    model2.compile(loss='categorical_crossentropy',\n",
    "                 optimizer='adam',\n",
    "                 metrics = ['accuracy'])\n",
    "    return model2 #생성한 모델과 같은 모델을 적어줘야함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ebe9a2cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 8s 157us/sample - loss: 0.3124 - accuracy: 0.9129\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 7s 148us/sample - loss: 0.1490 - accuracy: 0.9613\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 7s 149us/sample - loss: 0.1117 - accuracy: 0.9721\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 7s 150us/sample - loss: 0.0912 - accuracy: 0.9780\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 7s 150us/sample - loss: 0.0820 - accuracy: 0.9804\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 7s 150us/sample - loss: 0.0672 - accuracy: 0.9836\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 7s 149us/sample - loss: 0.0566 - accuracy: 0.9868\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 7s 149us/sample - loss: 0.0545 - accuracy: 0.9871\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 7s 150us/sample - loss: 0.0498 - accuracy: 0.9883\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 7s 151us/sample - loss: 0.0486 - accuracy: 0.9889\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 7s 149us/sample - loss: 0.0468 - accuracy: 0.9901\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 7s 146us/sample - loss: 0.0443 - accuracy: 0.9912\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 7s 146us/sample - loss: 0.0400 - accuracy: 0.9911\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 7s 147us/sample - loss: 0.0410 - accuracy: 0.9917\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 7s 147us/sample - loss: 0.0342 - accuracy: 0.9927\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 7s 148us/sample - loss: 0.0333 - accuracy: 0.9929\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 7s 148us/sample - loss: 0.0336 - accuracy: 0.9929\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 7s 150us/sample - loss: 0.0364 - accuracy: 0.9932\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 7s 151us/sample - loss: 0.0318 - accuracy: 0.9924\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 7s 152us/sample - loss: 0.0352 - accuracy: 0.9933\n",
      "12000/12000 [==============================] - 1s 105us/sample - loss: 0.1650 - accuracy: 0.9782\n",
      "Train on 48000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 8s 159us/sample - loss: 0.3252 - accuracy: 0.9113\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 7s 146us/sample - loss: 0.1492 - accuracy: 0.9628\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 7s 146us/sample - loss: 0.1124 - accuracy: 0.9722\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 7s 147us/sample - loss: 0.0941 - accuracy: 0.9777\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 7s 147us/sample - loss: 0.0798 - accuracy: 0.9808\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 7s 147us/sample - loss: 0.0690 - accuracy: 0.9831\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 7s 147us/sample - loss: 0.0602 - accuracy: 0.9860\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 7s 146us/sample - loss: 0.0554 - accuracy: 0.9872\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 7s 145us/sample - loss: 0.0541 - accuracy: 0.9877\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 7s 147us/sample - loss: 0.0508 - accuracy: 0.9890\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 7s 150us/sample - loss: 0.0469 - accuracy: 0.9901\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 7s 153us/sample - loss: 0.0425 - accuracy: 0.9907\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 7s 146us/sample - loss: 0.0390 - accuracy: 0.9911\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 7s 145us/sample - loss: 0.0340 - accuracy: 0.9925\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 7s 147us/sample - loss: 0.0395 - accuracy: 0.9921\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 7s 145us/sample - loss: 0.0440 - accuracy: 0.9918\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 7s 145us/sample - loss: 0.0512 - accuracy: 0.9859\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 7s 146us/sample - loss: 0.0389 - accuracy: 0.9920\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 7s 147us/sample - loss: 0.0412 - accuracy: 0.9917\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 7s 148us/sample - loss: 0.0673 - accuracy: 0.9857\n",
      "12000/12000 [==============================] - 1s 102us/sample - loss: 0.2270 - accuracy: 0.9734\n",
      "Train on 48000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 8s 162us/sample - loss: 0.3043 - accuracy: 0.9177\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 7s 151us/sample - loss: 0.1507 - accuracy: 0.9622\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 7s 150us/sample - loss: 0.1173 - accuracy: 0.9712\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 7s 149us/sample - loss: 0.0917 - accuracy: 0.9779\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 7s 148us/sample - loss: 0.0769 - accuracy: 0.9806\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 7s 149us/sample - loss: 0.0709 - accuracy: 0.9827\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 7s 150us/sample - loss: 0.0598 - accuracy: 0.9858\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 7s 148us/sample - loss: 0.0584 - accuracy: 0.9866\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 7s 149us/sample - loss: 0.0528 - accuracy: 0.9883\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 7s 149us/sample - loss: 0.0462 - accuracy: 0.9889\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 7s 149us/sample - loss: 0.0455 - accuracy: 0.9903\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 7s 151us/sample - loss: 0.0439 - accuracy: 0.9902\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 7s 151us/sample - loss: 0.0401 - accuracy: 0.9918\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 7s 151us/sample - loss: 0.0359 - accuracy: 0.9928\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 7s 149us/sample - loss: 0.0395 - accuracy: 0.9920\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 7s 149us/sample - loss: 0.0384 - accuracy: 0.9921\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 7s 150us/sample - loss: 0.0366 - accuracy: 0.9930\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 7s 153us/sample - loss: 0.0348 - accuracy: 0.9933\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 7s 151us/sample - loss: 0.0377 - accuracy: 0.9924\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 7s 154us/sample - loss: 0.0313 - accuracy: 0.9935\n",
      "12000/12000 [==============================] - 1s 101us/sample - loss: 0.2117 - accuracy: 0.9751\n",
      "Train on 48000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 8s 158us/sample - loss: 0.3243 - accuracy: 0.9110\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 7s 155us/sample - loss: 0.1523 - accuracy: 0.9618\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 7s 152us/sample - loss: 0.1175 - accuracy: 0.9706\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 7s 155us/sample - loss: 0.0938 - accuracy: 0.9769\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 7s 153us/sample - loss: 0.0791 - accuracy: 0.9813\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 7s 151us/sample - loss: 0.0664 - accuracy: 0.9838\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 7s 151us/sample - loss: 0.0644 - accuracy: 0.9857\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 7s 149us/sample - loss: 0.0542 - accuracy: 0.9870\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 7s 149us/sample - loss: 0.0542 - accuracy: 0.9880\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 7s 148us/sample - loss: 0.0543 - accuracy: 0.9884\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 7s 149us/sample - loss: 0.0419 - accuracy: 0.9905\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 7s 149us/sample - loss: 0.0467 - accuracy: 0.9901\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 7s 151us/sample - loss: 0.0418 - accuracy: 0.9912\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 7s 151us/sample - loss: 0.0389 - accuracy: 0.9917\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 7s 150us/sample - loss: 0.0397 - accuracy: 0.9920\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 7s 148us/sample - loss: 0.0360 - accuracy: 0.9928\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 7s 148us/sample - loss: 0.0429 - accuracy: 0.9914\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 7s 149us/sample - loss: 0.0409 - accuracy: 0.9916\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 7s 150us/sample - loss: 0.0355 - accuracy: 0.9934\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 7s 149us/sample - loss: 0.0450 - accuracy: 0.9919\n",
      "12000/12000 [==============================] - 1s 102us/sample - loss: 0.1799 - accuracy: 0.9787\n",
      "Train on 48000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 8s 156us/sample - loss: 0.3316 - accuracy: 0.9095\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 7s 148us/sample - loss: 0.1535 - accuracy: 0.9624\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 7s 150us/sample - loss: 0.1178 - accuracy: 0.9705\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 7s 148us/sample - loss: 0.0943 - accuracy: 0.9757\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 7s 150us/sample - loss: 0.0807 - accuracy: 0.9803\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 7s 150us/sample - loss: 0.0772 - accuracy: 0.9824\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 7s 149us/sample - loss: 0.0650 - accuracy: 0.9844\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 7s 149us/sample - loss: 0.0576 - accuracy: 0.9863\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 7s 150us/sample - loss: 0.0520 - accuracy: 0.9883\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 7s 149us/sample - loss: 0.0510 - accuracy: 0.9886\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 7s 148us/sample - loss: 0.0465 - accuracy: 0.9903\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 7s 147us/sample - loss: 0.0401 - accuracy: 0.9913\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 7s 149us/sample - loss: 0.0442 - accuracy: 0.9914\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 7s 151us/sample - loss: 0.0354 - accuracy: 0.9926\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 7s 150us/sample - loss: 0.0375 - accuracy: 0.9920\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 7s 151us/sample - loss: 0.0361 - accuracy: 0.9925\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 7s 148us/sample - loss: 0.0343 - accuracy: 0.9932\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 7s 150us/sample - loss: 0.0515 - accuracy: 0.9912\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 7s 150us/sample - loss: 0.0358 - accuracy: 0.9930\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 7s 151us/sample - loss: 0.0391 - accuracy: 0.9921\n",
      "12000/12000 [==============================] - 1s 101us/sample - loss: 0.2480 - accuracy: 0.9703\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "# KerasClassifier(딥러닝 모델 함수, epochs, batch_size)\n",
    "#딥러닝은 모델을 직접 설계한 것을 집어넣어야하기 때문에 함수를 만듬\n",
    "model3=KerasClassifier(build_fn = deep_model, epochs = 20, batch_size = 10)\n",
    "\n",
    "# cross_val_score(모델, 학습데이터, 정답데이터, cv = Kfold를 사용한 변수)\n",
    "#\n",
    "# 몇개로 어떻게 구분할건인지\n",
    "#KForld(n_split = 몇개로 나눌것인지, shuffle = 데이터를 섞을건지 rnadomstate)\n",
    "fold = KFold(n_splits = 5,shuffle= True,random_state=0)\n",
    "\n",
    "score =cross_val_score(model3,X_train,y_train,cv=fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4bf2fa53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.97816664, 0.97341669, 0.97508335, 0.97866666, 0.97025001])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34f2bc0",
   "metadata": {},
   "source": [
    "### 베스트 모델 찾아서 저장하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0f4b57ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "\n",
    "# 모델을 저장할 폴더명\n",
    "MODEL_FOLDER = './model'\n",
    "\n",
    "# 해당 폴더가 없다면 해당 폴더를 생성\n",
    "if not os.path.exists(MODEL_FOLDER) :\n",
    "    os.mkdir(MODEL_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f20ab567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장할 파일 명 설정\n",
    " #{epoch:04d} : 반복수를 4자리로 표시\n",
    "# {val_accuracy:.4f}:검증 정확도를 소수점 4째자리까지 표시\n",
    "#hdf5 파일형식\n",
    "modelpath = MODEL_FOLDER + './handnum-{epoch:04d}-{val_accuracy:4f}.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5cffef40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 베스트 모델을 찾아서 만들어둔 파일 명으로 저장\n",
    "# ModelCheckpoint(filepath = 파일 경로, monitor = 기준값,save_bast_only=True)\n",
    "#save_bast_only=True : 더 나은 결과값만 저장\n",
    "mc = ModelCheckpoint(filepath = modelpath,\n",
    "                    monitor = 'val_accuracy',\n",
    "                    save_best_only = True,\n",
    "                    verbose = 1) #verbose=1 진행결과를 보지 않겠다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c3c92da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EarlyStopping(monitor,patience = 기다리는 횟수)\n",
    "# patience = 20 : monitor 에 적은 기준에 따라 학습 결과가 더 나아지지 않더라도 \n",
    "#20번은 돌려보겠다.\n",
    "# patience가 있어야지만 조금씩 나아진 결과를 확인할 수 있다.\n",
    "#EarlyStopping 한 번 안좋아지면 멈춤\n",
    "es = EarlyStopping(monitor='val_accuracy',\n",
    "                  patience = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "067b24b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40199 samples, validate on 19801 samples\n",
      "Epoch 1/1000\n",
      "40050/40199 [============================>.] - ETA: 0s - loss: 0.0128 - accuracy: 0.9971\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.99747, saving model to ./model./handnum-0001-0.997475.hdf5\n",
      "40199/40199 [==============================] - 2s 55us/sample - loss: 0.0128 - accuracy: 0.9971 - val_loss: 0.0085 - val_accuracy: 0.9975\n",
      "Epoch 2/1000\n",
      "39400/40199 [============================>.] - ETA: 0s - loss: 0.0062 - accuracy: 0.9985\n",
      "Epoch 00002: val_accuracy improved from 0.99747 to 0.99803, saving model to ./model./handnum-0002-0.998030.hdf5\n",
      "40199/40199 [==============================] - 2s 50us/sample - loss: 0.0062 - accuracy: 0.9985 - val_loss: 0.0085 - val_accuracy: 0.9980\n",
      "Epoch 3/1000\n",
      "39950/40199 [============================>.] - ETA: 0s - loss: 0.0052 - accuracy: 0.9989\n",
      "Epoch 00003: val_accuracy did not improve from 0.99803\n",
      "40199/40199 [==============================] - 2s 49us/sample - loss: 0.0053 - accuracy: 0.9989 - val_loss: 0.0156 - val_accuracy: 0.9968\n",
      "Epoch 4/1000\n",
      "40050/40199 [============================>.] - ETA: 0s - loss: 0.0107 - accuracy: 0.9973\n",
      "Epoch 00004: val_accuracy improved from 0.99803 to 0.99828, saving model to ./model./handnum-0004-0.998283.hdf5\n",
      "40199/40199 [==============================] - 2s 49us/sample - loss: 0.0107 - accuracy: 0.9973 - val_loss: 0.0073 - val_accuracy: 0.9983\n",
      "Epoch 5/1000\n",
      "40100/40199 [============================>.] - ETA: 0s - loss: 0.0111 - accuracy: 0.9977\n",
      "Epoch 00005: val_accuracy did not improve from 0.99828\n",
      "40199/40199 [==============================] - 2s 48us/sample - loss: 0.0111 - accuracy: 0.9977 - val_loss: 0.0229 - val_accuracy: 0.9958\n",
      "Epoch 6/1000\n",
      "40000/40199 [============================>.] - ETA: 0s - loss: 0.0068 - accuracy: 0.9984\n",
      "Epoch 00006: val_accuracy did not improve from 0.99828\n",
      "40199/40199 [==============================] - 2s 49us/sample - loss: 0.0069 - accuracy: 0.9984 - val_loss: 0.0307 - val_accuracy: 0.9957\n",
      "Epoch 7/1000\n",
      "40150/40199 [============================>.] - ETA: 0s - loss: 0.0097 - accuracy: 0.9983\n",
      "Epoch 00007: val_accuracy did not improve from 0.99828\n",
      "40199/40199 [==============================] - 2s 48us/sample - loss: 0.0097 - accuracy: 0.9983 - val_loss: 0.0147 - val_accuracy: 0.9963\n",
      "Epoch 8/1000\n",
      "39750/40199 [============================>.] - ETA: 0s - loss: 0.0087 - accuracy: 0.9983\n",
      "Epoch 00008: val_accuracy did not improve from 0.99828\n",
      "40199/40199 [==============================] - 2s 49us/sample - loss: 0.0087 - accuracy: 0.9983 - val_loss: 0.0204 - val_accuracy: 0.9958\n",
      "Epoch 9/1000\n",
      "39350/40199 [============================>.] - ETA: 0s - loss: 0.0091 - accuracy: 0.9979\n",
      "Epoch 00009: val_accuracy did not improve from 0.99828\n",
      "40199/40199 [==============================] - 2s 49us/sample - loss: 0.0092 - accuracy: 0.9979 - val_loss: 0.0274 - val_accuracy: 0.9940\n",
      "Epoch 10/1000\n",
      "39150/40199 [============================>.] - ETA: 0s - loss: 0.0062 - accuracy: 0.9984\n",
      "Epoch 00010: val_accuracy did not improve from 0.99828\n",
      "40199/40199 [==============================] - 2s 50us/sample - loss: 0.0066 - accuracy: 0.9984 - val_loss: 0.0263 - val_accuracy: 0.9957\n",
      "Epoch 11/1000\n",
      "39850/40199 [============================>.] - ETA: 0s - loss: 0.0135 - accuracy: 0.9976\n",
      "Epoch 00011: val_accuracy did not improve from 0.99828\n",
      "40199/40199 [==============================] - 2s 48us/sample - loss: 0.0138 - accuracy: 0.9976 - val_loss: 0.0342 - val_accuracy: 0.9934\n",
      "Epoch 12/1000\n",
      "40000/40199 [============================>.] - ETA: 0s - loss: 0.0056 - accuracy: 0.9987\n",
      "Epoch 00012: val_accuracy did not improve from 0.99828\n",
      "40199/40199 [==============================] - 2s 50us/sample - loss: 0.0067 - accuracy: 0.9986 - val_loss: 0.0394 - val_accuracy: 0.9936\n",
      "Epoch 13/1000\n",
      "39400/40199 [============================>.] - ETA: 0s - loss: 0.0104 - accuracy: 0.9978\n",
      "Epoch 00013: val_accuracy did not improve from 0.99828\n",
      "40199/40199 [==============================] - 2s 50us/sample - loss: 0.0102 - accuracy: 0.9978 - val_loss: 0.0202 - val_accuracy: 0.9955\n",
      "Epoch 14/1000\n",
      "40050/40199 [============================>.] - ETA: 0s - loss: 0.0075 - accuracy: 0.9986\n",
      "Epoch 00014: val_accuracy did not improve from 0.99828\n",
      "40199/40199 [==============================] - 2s 48us/sample - loss: 0.0075 - accuracy: 0.9986 - val_loss: 0.0492 - val_accuracy: 0.9913\n",
      "Epoch 15/1000\n",
      "40100/40199 [============================>.] - ETA: 0s - loss: 0.0064 - accuracy: 0.9988\n",
      "Epoch 00015: val_accuracy did not improve from 0.99828\n",
      "40199/40199 [==============================] - 2s 48us/sample - loss: 0.0064 - accuracy: 0.9988 - val_loss: 0.0266 - val_accuracy: 0.9949\n",
      "Epoch 16/1000\n",
      "39750/40199 [============================>.] - ETA: 0s - loss: 0.0115 - accuracy: 0.9984\n",
      "Epoch 00016: val_accuracy did not improve from 0.99828\n",
      "40199/40199 [==============================] - 2s 49us/sample - loss: 0.0114 - accuracy: 0.9985 - val_loss: 0.0231 - val_accuracy: 0.9958\n",
      "Epoch 17/1000\n",
      "38850/40199 [===========================>..] - ETA: 0s - loss: 0.0043 - accuracy: 0.9992\n",
      "Epoch 00017: val_accuracy did not improve from 0.99828\n",
      "40199/40199 [==============================] - 2s 50us/sample - loss: 0.0047 - accuracy: 0.9991 - val_loss: 0.0429 - val_accuracy: 0.9924\n",
      "Epoch 18/1000\n",
      "40000/40199 [============================>.] - ETA: 0s - loss: 0.0108 - accuracy: 0.9978\n",
      "Epoch 00018: val_accuracy did not improve from 0.99828\n",
      "40199/40199 [==============================] - 2s 50us/sample - loss: 0.0108 - accuracy: 0.9978 - val_loss: 0.0453 - val_accuracy: 0.9927\n",
      "Epoch 19/1000\n",
      "39700/40199 [============================>.] - ETA: 0s - loss: 0.0072 - accuracy: 0.9989\n",
      "Epoch 00019: val_accuracy did not improve from 0.99828\n",
      "40199/40199 [==============================] - 2s 49us/sample - loss: 0.0072 - accuracy: 0.9989 - val_loss: 0.0329 - val_accuracy: 0.9940\n",
      "Epoch 20/1000\n",
      "39700/40199 [============================>.] - ETA: 0s - loss: 0.0041 - accuracy: 0.9993\n",
      "Epoch 00020: val_accuracy did not improve from 0.99828\n",
      "40199/40199 [==============================] - 2s 51us/sample - loss: 0.0040 - accuracy: 0.9993 - val_loss: 0.0275 - val_accuracy: 0.9951\n",
      "Epoch 21/1000\n",
      "39200/40199 [============================>.] - ETA: 0s - loss: 0.0114 - accuracy: 0.9982\n",
      "Epoch 00021: val_accuracy did not improve from 0.99828\n",
      "40199/40199 [==============================] - 2s 49us/sample - loss: 0.0113 - accuracy: 0.9982 - val_loss: 0.0502 - val_accuracy: 0.9919\n",
      "Epoch 22/1000\n",
      "39900/40199 [============================>.] - ETA: 0s - loss: 0.0101 - accuracy: 0.9982\n",
      "Epoch 00022: val_accuracy did not improve from 0.99828\n",
      "40199/40199 [==============================] - 2s 49us/sample - loss: 0.0101 - accuracy: 0.9982 - val_loss: 0.0404 - val_accuracy: 0.9928\n",
      "Epoch 23/1000\n",
      "39900/40199 [============================>.] - ETA: 0s - loss: 0.0087 - accuracy: 0.9990\n",
      "Epoch 00023: val_accuracy did not improve from 0.99828\n",
      "40199/40199 [==============================] - 2s 49us/sample - loss: 0.0086 - accuracy: 0.9990 - val_loss: 0.0825 - val_accuracy: 0.9903\n",
      "Epoch 24/1000\n",
      "39800/40199 [============================>.] - ETA: 0s - loss: 0.0091 - accuracy: 0.9986\n",
      "Epoch 00024: val_accuracy did not improve from 0.99828\n",
      "40199/40199 [==============================] - 2s 49us/sample - loss: 0.0090 - accuracy: 0.9986 - val_loss: 0.0335 - val_accuracy: 0.9949\n"
     ]
    }
   ],
   "source": [
    "#학습\n",
    "#validation_split=0.33: 전체 데이터중에서 33%를 검증데이터로 활용 평가\n",
    "history = model2.fit(X_train,y_train,epochs = 1000,batch_size = 50,\n",
    "                     validation_split=0.33,\n",
    "                    callbacks=[mc,es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b8c48010",
   "metadata": {},
   "outputs": [],
   "source": [
    "#저장할려면 모델 생성부터 다시 돌려야함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e10654b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG16 모델 전이학습\n",
    "from tensorflow.keras.applications import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2515e329",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base = VGG16(weights = 'imagenet',\n",
    "                 include_top = False,\n",
    "                 input_shape=(35,35,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e2561759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 35, 35, 3)]       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 35, 35, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 35, 35, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 17, 17, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 17, 17, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 17, 17, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 4, 4, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1e28cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
