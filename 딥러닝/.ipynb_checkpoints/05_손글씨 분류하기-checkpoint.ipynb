{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "100ff930",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a33ff79",
   "metadata": {},
   "source": [
    "### 손글씨 데이터 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48a61d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "((X_train,y_train),(X_test,y_test)) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f77b8bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 손글씨 사진 데이터\n",
    "# 60000: 데이터의 수\n",
    "# 28 X 28 사진 데이터\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3b390a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 28, 28), (10000,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc35eb4",
   "metadata": {},
   "source": [
    "#### 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05762c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46a98328",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2762b339748>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# cmap = plt.cm.binary : 색상 > 흑백\n",
    "plt.imshow(X_train[0], cmap = plt.cm.binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23f7f027",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0 ~ 255까지의 숫자로 이루어져 있음\n",
    "# 0이 흰색\n",
    "# 255가 검은색\n",
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b75fd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기계는 0과 1사이의 숫자를 좋아함\n",
    "# 0 ~ 255까지의 숫자를 0 ~ 1까지로 만들어줌 \n",
    "# 전체 데이터를 255로 나눠줌\n",
    "X_train = X_train.astype('float32')/255\n",
    "X_test = X_test.astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61fa92f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 28 X 28의 2차원 데이터를 784의 1차원 데이터로 만들어줄 필요가 있음\n",
    "# input_dim에 집어넣기 위해서 !\n",
    "X_train = X_train.reshape((60000,28*28))\n",
    "X_test = X_test.reshape((10000,784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98803d3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97f6277d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.unique(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "043aca38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정답 데이터 원핫 인코딩\n",
    "import pandas as pd \n",
    "y_train = pd.get_dummies(y_train)\n",
    "y_test = pd.get_dummies(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1078c868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력층 개수: 784\n",
    "# 출력층 개수: 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c28232f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "seed = 100\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c6e47c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델설계\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "model = Sequential()\n",
    "# 입력층, 중간층의 활성화 함수: sigmoid\n",
    "#입력층\n",
    "model.add(Dense(units=1000, input_dim=784, activation='sigmoid' ))\n",
    "#중간층\n",
    "model.add(Dense(units= 500, activation='sigmoid'))\n",
    "model.add(Dense(units=250, activation = 'sigmoid'))\n",
    "model.add(Dense(units=125, activation = 'sigmoid'))\n",
    "model.add(Dense(units=60, activation = 'sigmoid'))\n",
    "model.add(Dense(units=30, activation = 'sigmoid'))\n",
    "model.add(Dense(units=15, activation ='sigmoid'))\n",
    "# 출력층의 활성화함수: softmax\n",
    "model.add(Dense(units=10,activation ='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9fa88d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 1000)              785000    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 500)               500500    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 250)               125250    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 125)               31375     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 60)                7560      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 30)                1830      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 15)                465       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                160       \n",
      "=================================================================\n",
      "Total params: 1,452,140\n",
      "Trainable params: 1,452,140\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0290e113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 학습 방법 설정\n",
    "# loss = categorical_crossentropy\n",
    "# optimizer = 'adam'\n",
    "# metrics = accracy\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "46b37011",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 784), (10000, 784), (60000, 10), (10000, 10))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "98e4ebce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 1.7532 - accuracy: 0.2993 - val_loss: 1.2992 - val_accuracy: 0.4436\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 1.1201 - accuracy: 0.5009 - val_loss: 0.8245 - val_accuracy: 0.6605\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.5286 - accuracy: 0.8233 - val_loss: 0.3630 - val_accuracy: 0.9145\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.2494 - accuracy: 0.9543 - val_loss: 0.1870 - val_accuracy: 0.9614\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.1433 - accuracy: 0.9700 - val_loss: 0.1478 - val_accuracy: 0.9670\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.1008 - accuracy: 0.9780 - val_loss: 0.1215 - val_accuracy: 0.9728\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.0788 - accuracy: 0.9821 - val_loss: 0.1139 - val_accuracy: 0.9732\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.0617 - accuracy: 0.9858 - val_loss: 0.1060 - val_accuracy: 0.9772\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.0476 - accuracy: 0.9890 - val_loss: 0.1320 - val_accuracy: 0.9741\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.0429 - accuracy: 0.9901 - val_loss: 0.1325 - val_accuracy: 0.9701\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.0362 - accuracy: 0.9921 - val_loss: 0.1040 - val_accuracy: 0.9796\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.0339 - accuracy: 0.9921 - val_loss: 0.1097 - val_accuracy: 0.9765\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.0268 - accuracy: 0.9939 - val_loss: 0.1079 - val_accuracy: 0.9792\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.0238 - accuracy: 0.9949 - val_loss: 0.1149 - val_accuracy: 0.9786\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.0235 - accuracy: 0.9950 - val_loss: 0.1223 - val_accuracy: 0.9771\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.0213 - accuracy: 0.9954 - val_loss: 0.1201 - val_accuracy: 0.9787\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.0187 - accuracy: 0.9958 - val_loss: 0.1073 - val_accuracy: 0.9799\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.0164 - accuracy: 0.9964 - val_loss: 0.1426 - val_accuracy: 0.9777\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.0162 - accuracy: 0.9964 - val_loss: 0.1160 - val_accuracy: 0.9805\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.0144 - accuracy: 0.9970 - val_loss: 0.1170 - val_accuracy: 0.9803\n"
     ]
    }
   ],
   "source": [
    "# 모델 학습\n",
    "# epochs = 20 \n",
    "history1 = model.fit(X_train,y_train,epochs=20, validation_data=[X_test,y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "281235c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 36us/sample - loss: 0.1170 - accuracy: 0.9803\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.11702795489020645, 0.9803]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 평가\n",
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2a931390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.2744 - accuracy: 0.9201 - val_loss: 0.1288 - val_accuracy: 0.9653\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.1171 - accuracy: 0.9682 - val_loss: 0.1340 - val_accuracy: 0.9662\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.0883 - accuracy: 0.9766 - val_loss: 0.0955 - val_accuracy: 0.9725\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.0677 - accuracy: 0.9814 - val_loss: 0.1162 - val_accuracy: 0.9701\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.0566 - accuracy: 0.9847 - val_loss: 0.0764 - val_accuracy: 0.9818\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.0465 - accuracy: 0.9877 - val_loss: 0.0810 - val_accuracy: 0.9815\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.0419 - accuracy: 0.9886 - val_loss: 0.1013 - val_accuracy: 0.9770\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.0375 - accuracy: 0.9900 - val_loss: 0.0926 - val_accuracy: 0.9806\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.0309 - accuracy: 0.9916 - val_loss: 0.0898 - val_accuracy: 0.9793\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.0321 - accuracy: 0.9917 - val_loss: 0.1076 - val_accuracy: 0.9785\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.0283 - accuracy: 0.9922 - val_loss: 0.0882 - val_accuracy: 0.9832\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.0250 - accuracy: 0.9941 - val_loss: 0.1071 - val_accuracy: 0.9786\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.0251 - accuracy: 0.9934 - val_loss: 0.1142 - val_accuracy: 0.9834\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.0237 - accuracy: 0.9943 - val_loss: 0.1119 - val_accuracy: 0.9764\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.0200 - accuracy: 0.9950 - val_loss: 0.1093 - val_accuracy: 0.9836\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.0210 - accuracy: 0.9946 - val_loss: 0.1156 - val_accuracy: 0.9809\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.0192 - accuracy: 0.9955 - val_loss: 0.1250 - val_accuracy: 0.9811\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: 0.0170 - accuracy: 0.9958 - val_loss: 0.1135 - val_accuracy: 0.9830\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.0172 - accuracy: 0.9964 - val_loss: 0.1059 - val_accuracy: 0.9848\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.0186 - accuracy: 0.9955 - val_loss: 0.1102 - val_accuracy: 0.9845\n"
     ]
    }
   ],
   "source": [
    "# 모든 조건은 동일 \n",
    "# model2라는 딥러닝 모델 설계\n",
    "# 입력층과 중간층의 활성화함수 sigmoid > relu\n",
    "# history2 = model2.fit()\n",
    "model2 = Sequential()\n",
    "# 입력층, 중간층의 활성화 함수: relu\n",
    "#입력층\n",
    "model2.add(Dense(units=1000, input_dim=784, activation='relu' ))\n",
    "#중간층\n",
    "model2.add(Dense(units= 500, activation='relu'))\n",
    "model2.add(Dense(units=250, activation = 'relu'))\n",
    "model2.add(Dense(units=125, activation = 'relu'))\n",
    "model2.add(Dense(units=60, activation = 'relu'))\n",
    "model2.add(Dense(units=30, activation = 'relu'))\n",
    "model2.add(Dense(units=15, activation ='relu'))\n",
    "# 출력층의 활성화함수: softmax\n",
    "model2.add(Dense(units=10,activation ='softmax'))\n",
    "\n",
    "model2.compile(loss='categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics = ['accuracy'])\n",
    "\n",
    "history2 = model2.fit(X_train,y_train,epochs=20, validation_data=[X_test,y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d806f606",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model1 > 입력층, 중간층 활성화함수: sigmoid >history1\n",
    "#model2 > 입력층, 중간층 활성화함수: relu>history2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1b8de841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "plt.plot(range(20),history1.history['accuracy'],label='model1')\n",
    "plt.plot(range(20),history2.history['accuracy'],label='model2')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9fa22540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.753200602722168,\n",
       " 1.120060179201762,\n",
       " 0.5286010523319244,\n",
       " 0.24939538956681886,\n",
       " 0.14330857411722342,\n",
       " 0.10081623352915049,\n",
       " 0.07879445401728154,\n",
       " 0.06173464107438922,\n",
       " 0.04761203887611628,\n",
       " 0.042932600070163605,\n",
       " 0.036155165442451835,\n",
       " 0.0339064423772196,\n",
       " 0.026777510681375863,\n",
       " 0.023767310974871118,\n",
       " 0.023474711199849844,\n",
       " 0.021256701333262025,\n",
       " 0.01871345538577686,\n",
       " 0.0163862412152191,\n",
       " 0.01621756602569173,\n",
       " 0.014359307182673364]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model1에서 epochs를 돌린 결과가 들어있음\n",
    "# history라는 함수를 통해서 accuracy\n",
    "history1.history['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d07f4b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# jpg > 컬러사진\n",
    "# gif > 흑백사진"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780a43d4",
   "metadata": {},
   "source": [
    "직접 그린 그림 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0218c535",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image as pimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9259b80d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x27806f1bd30>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_num = pimg.open('num3.gif')\n",
    "plt.imshow(img_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c2da584c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAMAAABF0y+mAAADAFBMVEUAAAAAADMAAGYAAJkAAMwAAP8AKwAAKzMAK2YAK5kAK8wAK/8AVQAAVTMAVWYAVZkAVcwAVf8AgAAAgDMAgGYAgJkAgMwAgP8AqgAAqjMAqmYAqpkAqswAqv8A1QAA1TMA1WYA1ZkA1cwA1f8A/wAA/zMA/2YA/5kA/8wA//8zAAAzADMzAGYzAJkzAMwzAP8zKwAzKzMzK2YzK5kzK8wzK/8zVQAzVTMzVWYzVZkzVcwzVf8zgAAzgDMzgGYzgJkzgMwzgP8zqgAzqjMzqmYzqpkzqswzqv8z1QAz1TMz1WYz1Zkz1cwz1f8z/wAz/zMz/2Yz/5kz/8wz//9mAABmADNmAGZmAJlmAMxmAP9mKwBmKzNmK2ZmK5lmK8xmK/9mVQBmVTNmVWZmVZlmVcxmVf9mgABmgDNmgGZmgJlmgMxmgP9mqgBmqjNmqmZmqplmqsxmqv9m1QBm1TNm1WZm1Zlm1cxm1f9m/wBm/zNm/2Zm/5lm/8xm//+ZAACZADOZAGaZAJmZAMyZAP+ZKwCZKzOZK2aZK5mZK8yZK/+ZVQCZVTOZVWaZVZmZVcyZVf+ZgACZgDOZgGaZgJmZgMyZgP+ZqgCZqjOZqmaZqpmZqsyZqv+Z1QCZ1TOZ1WaZ1ZmZ1cyZ1f+Z/wCZ/zOZ/2aZ/5mZ/8yZ///MAADMADPMAGbMAJnMAMzMAP/MKwDMKzPMK2bMK5nMK8zMK//MVQDMVTPMVWbMVZnMVczMVf/MgADMgDPMgGbMgJnMgMzMgP/MqgDMqjPMqmbMqpnMqszMqv/M1QDM1TPM1WbM1ZnM1czM1f/M/wDM/zPM/2bM/5nM/8zM////AAD/ADP/AGb/AJn/AMz/AP//KwD/KzP/K2b/K5n/K8z/K///VQD/VTP/VWb/VZn/Vcz/Vf//gAD/gDP/gGb/gJn/gMz/gP//qgD/qjP/qmb/qpn/qsz/qv//1QD/1TP/1Wb/1Zn/1cz/1f///wD//zP//2b//5n//8z///8AAAAAAAAAAAAAAADZ9vIoAAAA/XRSTlP///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////8A9k80AwAAAGpJREFUeJy10rERwCAIBVAql0nFSqyUyn2oshJNziMYTsFKf/s8/HKCLAInsSJ8ueqIDC4jlhXeACQ2Ii1UMmQdTjOyXevN0AyDd7ZKmhrgfyBB5RRlMzK2lk9cyG1+RuoWbYgCOvzBtuML2EyAfcHoTIAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.GifImagePlugin.GifImageFile image mode=P size=28x28 at 0x2762CA64470>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 28*28 2차원 데이터 > 784의 1차원 데이터로 변환\n",
    "# 0 ~ 255사이의 픽셀값 > 0 ~1사이의 픽셀값-\n",
    "img_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bf5a3018",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
       "        251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
       "        251, 251],\n",
       "       [251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
       "        251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
       "        251, 251],\n",
       "       [251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
       "        251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
       "        251, 251],\n",
       "       [251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
       "        251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
       "        251, 251],\n",
       "       [251, 251, 251, 251, 251, 153,  49,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  43, 153, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
       "        251, 251],\n",
       "       [251, 251, 251, 251, 196,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
       "        251, 251],\n",
       "       [251, 251, 251, 251,   6,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
       "        251, 251],\n",
       "       [251, 251, 251, 251, 147,   0,   0,  98, 251, 251, 251, 251, 251,\n",
       "        196,   0,   0,   0, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
       "        251, 251],\n",
       "       [251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
       "          6,   0,   0,   0, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
       "        251, 251],\n",
       "       [251, 251, 251, 251, 251, 251, 251, 251, 251, 196,   6,   0,   0,\n",
       "          0,   0,   0,  98, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
       "        251, 251],\n",
       "       [251, 251, 251, 251, 251, 251, 196,   6,   0,   0,   0,   0,   0,\n",
       "          0,   0,  98, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
       "        251, 251],\n",
       "       [251, 251, 251, 251, 251, 251,   6,   0,   0,   0,   0,   0,   0,\n",
       "          0,  49, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
       "        251, 251],\n",
       "       [251, 251, 251, 251, 251, 251, 147,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0, 153, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
       "        251, 251],\n",
       "       [251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 147,   0,   0,\n",
       "          0,   0,   0, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
       "        251, 251],\n",
       "       [251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 147,\n",
       "          0,   0,   0, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
       "        251, 251],\n",
       "       [251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
       "          0,   0,   0, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
       "        251, 251],\n",
       "       [251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
       "          0,   0,   0, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
       "        251, 251],\n",
       "       [251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
       "          0,   0,   0, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
       "        251, 251],\n",
       "       [251, 251, 251, 251, 251, 196,  49, 153, 251, 251, 251, 202,   0,\n",
       "          0,   0,   0, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
       "        251, 251],\n",
       "       [251, 251, 251, 251, 251,   6,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
       "        251, 251],\n",
       "       [251, 251, 251, 251, 251,  98,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  98, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
       "        251, 251],\n",
       "       [251, 251, 251, 251, 251, 251,  98,   0,   0,   0,   0,   0,   0,\n",
       "         98, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
       "        251, 251],\n",
       "       [251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
       "        251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
       "        251, 251],\n",
       "       [251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
       "        251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
       "        251, 251],\n",
       "       [251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
       "        251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
       "        251, 251],\n",
       "       [251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
       "        251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
       "        251, 251],\n",
       "       [251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
       "        251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
       "        251, 251],\n",
       "       [251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
       "        251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
       "        251, 251]], dtype=uint8)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num=np.array(img_num)\n",
    "num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "674ea43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기존에는 흰색 > 0 검은색>255\n",
    "# 지금은 흰색이 > 255 검은색 >0 \n",
    "num = 255 - num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "db09deb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1차원 데이터로 변환\n",
    "num = num.reshape(1,784)\n",
    "num = num.astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bccc44b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0, 99,  0,  0,  0,  0,  0,  0]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model2.predict(num)*100).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "444723ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3], dtype=int64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.predict_classes(num)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca963104",
   "metadata": {},
   "source": [
    "#### 모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e71d8c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.save('./model/model_handnum1.h5') #model폴더/파일이름.파일형식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f1e21f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 불러오기\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model3 = load_model('./model/model_handnum1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f8b52f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 2s 31us/sample - loss: 0.0066 - accuracy: 0.9981\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.00663785761614388, 0.99815]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.evaluate(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2c75a26a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 473\n",
      "60000/60000 [==============================] - 2s 32us/sample - loss: 0.0010 - accuracy: 0.9997\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.001041066051255196, 0.99965]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_youngsun=load_model('./model/youngsun.h5')\n",
    "model_youngsun.evaluate(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "050b8711",
   "metadata": {},
   "outputs": [],
   "source": [
    "#딥러닝에서 교차검증\n",
    "from sklearn.model_selection import KFold, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ec2987f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deep_model():\n",
    "    model2 = Sequential()\n",
    "# 입력층, 중간층의 활성화 함수: relu\n",
    "#입력층\n",
    "    model2.add(Dense(units=1000, input_dim=784, activation='relu' ))\n",
    "#중간층\n",
    "    model2.add(Dense(units= 500, activation='relu'))\n",
    "    model2.add(Dense(units=250, activation = 'relu'))\n",
    "    model2.add(Dense(units=125, activation = 'relu'))\n",
    "    model2.add(Dense(units=60, activation = 'relu'))\n",
    "    model2.add(Dense(units=30, activation = 'relu'))\n",
    "    model2.add(Dense(units=15, activation ='relu'))\n",
    "# 출력층의 활성화함수: softmax\n",
    "    model2.add(Dense(units=10,activation ='softmax'))\n",
    "\n",
    "    model2.compile(loss='categorical_crossentropy',\n",
    "                 optimizer='adam',\n",
    "                 metrics = ['accuracy'])\n",
    "    return model2 #생성한 모델과 같은 모델을 적어줘야함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ebe9a2cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 474\n",
      "Train on 48000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 8s 164us/sample - loss: 0.3137 - accuracy: 0.9119\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 8s 157us/sample - loss: 0.1506 - accuracy: 0.9621\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 7s 154us/sample - loss: 0.1142 - accuracy: 0.9724\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 7s 154us/sample - loss: 0.0906 - accuracy: 0.9775\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 7s 153us/sample - loss: 0.0777 - accuracy: 0.9805\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 7s 154us/sample - loss: 0.0629 - accuracy: 0.9841\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 7s 153us/sample - loss: 0.0600 - accuracy: 0.9854\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 7s 154us/sample - loss: 0.0544 - accuracy: 0.9868\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 7s 154us/sample - loss: 0.0531 - accuracy: 0.9875\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 7s 156us/sample - loss: 0.0466 - accuracy: 0.9893\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 8s 157us/sample - loss: 0.0476 - accuracy: 0.9899\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 7s 156us/sample - loss: 0.0419 - accuracy: 0.9908\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 7s 155us/sample - loss: 0.0381 - accuracy: 0.9916\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 7s 156us/sample - loss: 0.0430 - accuracy: 0.9913\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 8s 156us/sample - loss: 0.0433 - accuracy: 0.9913\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 7s 154us/sample - loss: 0.0311 - accuracy: 0.9933\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 7s 154us/sample - loss: 0.0405 - accuracy: 0.9918\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 7s 154us/sample - loss: 0.0352 - accuracy: 0.9930\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 7s 154us/sample - loss: 0.0365 - accuracy: 0.9932\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 7s 154us/sample - loss: 0.0559 - accuracy: 0.9868\n",
      "12000/12000 [==============================] - 1s 102us/sample - loss: 0.1484 - accuracy: 0.9812\n",
      "Train on 48000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 8s 164us/sample - loss: 0.3354 - accuracy: 0.9089\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 8s 159us/sample - loss: 0.1501 - accuracy: 0.9614\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 8s 160us/sample - loss: 0.1101 - accuracy: 0.9728\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 8s 157us/sample - loss: 0.0936 - accuracy: 0.9768\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 8s 166us/sample - loss: 0.0769 - accuracy: 0.9812\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 8s 158us/sample - loss: 0.0731 - accuracy: 0.9829\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 8s 159us/sample - loss: 0.0649 - accuracy: 0.9858\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 8s 159us/sample - loss: 0.0591 - accuracy: 0.9868\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 8s 160us/sample - loss: 0.0486 - accuracy: 0.9882\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 8s 160us/sample - loss: 0.0479 - accuracy: 0.9888\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 8s 157us/sample - loss: 0.0473 - accuracy: 0.9898\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 8s 160us/sample - loss: 0.0466 - accuracy: 0.9900\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 7s 156us/sample - loss: 0.0400 - accuracy: 0.9918\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 8s 158us/sample - loss: 0.0414 - accuracy: 0.9907\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 8s 158us/sample - loss: 0.0399 - accuracy: 0.9918\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 7s 156us/sample - loss: 0.0498 - accuracy: 0.9913\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 8s 158us/sample - loss: 0.0336 - accuracy: 0.9933\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 8s 158us/sample - loss: 0.0451 - accuracy: 0.9910\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 8s 162us/sample - loss: 0.0292 - accuracy: 0.9939\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 8s 169us/sample - loss: 0.0514 - accuracy: 0.9912\n",
      "12000/12000 [==============================] - 1s 104us/sample - loss: 0.1766 - accuracy: 0.9746\n",
      "Train on 48000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 8s 168us/sample - loss: 0.3075 - accuracy: 0.9155\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 7s 156us/sample - loss: 0.1507 - accuracy: 0.9619\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 8s 157us/sample - loss: 0.1163 - accuracy: 0.9702\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 8s 160us/sample - loss: 0.0947 - accuracy: 0.9761\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 7s 155us/sample - loss: 0.0782 - accuracy: 0.9801\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 7s 154us/sample - loss: 0.0705 - accuracy: 0.9835\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 7s 155us/sample - loss: 0.0595 - accuracy: 0.9863\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 7s 154us/sample - loss: 0.0537 - accuracy: 0.9875\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 7s 156us/sample - loss: 0.0487 - accuracy: 0.9888\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 7s 155us/sample - loss: 0.0474 - accuracy: 0.9894\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 7s 155us/sample - loss: 0.0461 - accuracy: 0.9900\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 7s 155us/sample - loss: 0.0414 - accuracy: 0.9910\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 7s 154us/sample - loss: 0.0413 - accuracy: 0.9909\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 8s 164us/sample - loss: 0.0399 - accuracy: 0.9912\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 7s 155us/sample - loss: 0.0398 - accuracy: 0.9920\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 7s 154us/sample - loss: 0.0415 - accuracy: 0.9919\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 7s 154us/sample - loss: 0.0306 - accuracy: 0.9936\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 7s 155us/sample - loss: 0.0409 - accuracy: 0.9923\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 7s 155us/sample - loss: 0.0329 - accuracy: 0.9938\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 7s 155us/sample - loss: 0.0331 - accuracy: 0.9936\n",
      "12000/12000 [==============================] - 1s 101us/sample - loss: 0.1608 - accuracy: 0.9750\n",
      "Train on 48000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 8s 161us/sample - loss: 0.3289 - accuracy: 0.9117\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 7s 153us/sample - loss: 0.1547 - accuracy: 0.9620\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 7s 153us/sample - loss: 0.1168 - accuracy: 0.9711\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 7s 153us/sample - loss: 0.0954 - accuracy: 0.9765\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 7s 153us/sample - loss: 0.0780 - accuracy: 0.9809\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 7s 153us/sample - loss: 0.0713 - accuracy: 0.9832\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 7s 153us/sample - loss: 0.0603 - accuracy: 0.9858\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 7s 153us/sample - loss: 0.0569 - accuracy: 0.9868\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 7s 154us/sample - loss: 0.0539 - accuracy: 0.9874\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 7s 153us/sample - loss: 0.0511 - accuracy: 0.9889\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 7s 153us/sample - loss: 0.0475 - accuracy: 0.9901\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000/48000 [==============================] - 7s 150us/sample - loss: 0.0437 - accuracy: 0.9910\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 7s 150us/sample - loss: 0.0451 - accuracy: 0.9902\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 7s 150us/sample - loss: 0.0377 - accuracy: 0.9916\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 7s 150us/sample - loss: 0.0356 - accuracy: 0.9926\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 7s 150us/sample - loss: 0.0364 - accuracy: 0.9923\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 7s 150us/sample - loss: 0.0430 - accuracy: 0.9915\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 7s 149us/sample - loss: 0.0328 - accuracy: 0.9925\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 7s 150us/sample - loss: 0.0303 - accuracy: 0.9939\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 7s 150us/sample - loss: 0.0418 - accuracy: 0.9924\n",
      "12000/12000 [==============================] - 1s 100us/sample - loss: 0.3052 - accuracy: 0.9729\n",
      "Train on 48000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 8s 158us/sample - loss: 0.3319 - accuracy: 0.9097\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 7s 151us/sample - loss: 0.1557 - accuracy: 0.9602\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 7s 151us/sample - loss: 0.1179 - accuracy: 0.9709\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 7s 150us/sample - loss: 0.0931 - accuracy: 0.9769\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 7s 152us/sample - loss: 0.0808 - accuracy: 0.9798\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 7s 153us/sample - loss: 0.0736 - accuracy: 0.9825\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 7s 154us/sample - loss: 0.0670 - accuracy: 0.9848\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 7s 154us/sample - loss: 0.0587 - accuracy: 0.9866\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 7s 150us/sample - loss: 0.0519 - accuracy: 0.9886\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 7s 151us/sample - loss: 0.0466 - accuracy: 0.9889\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 7s 151us/sample - loss: 0.0486 - accuracy: 0.9898\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 7s 151us/sample - loss: 0.0434 - accuracy: 0.9901\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 7s 151us/sample - loss: 0.0459 - accuracy: 0.9902\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 7s 151us/sample - loss: 0.0412 - accuracy: 0.9913\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 7s 151us/sample - loss: 0.0368 - accuracy: 0.9925\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 7s 151us/sample - loss: 0.0387 - accuracy: 0.9917\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 7s 151us/sample - loss: 0.0384 - accuracy: 0.9923\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 7s 151us/sample - loss: 0.0377 - accuracy: 0.9920\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 7s 151us/sample - loss: 0.0312 - accuracy: 0.9937\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 7s 151us/sample - loss: 0.0389 - accuracy: 0.9926\n",
      "12000/12000 [==============================] - 1s 101us/sample - loss: 0.1758 - accuracy: 0.9768\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "# KerasClassifier(딥러닝 모델 함수, epochs, batch_size)\n",
    "#딥러닝은 모델을 직접 설계한 것을 집어넣어야하기 때문에 함수를 만듬\n",
    "model3=KerasClassifier(build_fn = deep_model, epochs = 20, batch_size = 10)\n",
    "\n",
    "# cross_val_score(모델, 학습데이터, 정답데이터, cv = Kfold를 사용한 변수)\n",
    "#\n",
    "# 몇개로 어떻게 구분할건인지\n",
    "#KForld(n_split = 몇개로 나눌것인지, shuffle = 데이터를 섞을건지 rnadomstate)\n",
    "fold = KFold(n_splits = 5,shuffle= True,random_state=0)\n",
    "\n",
    "score =cross_val_score(model3,X_train,y_train,cv=fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4bf2fa53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.98116666, 0.97458333, 0.97500002, 0.97291666, 0.97675002])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34f2bc0",
   "metadata": {},
   "source": [
    "### 베스트 모델 찾아서 저장하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0f4b57ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "\n",
    "# 모델을 저장할 폴더명\n",
    "MODEL_FOLDER = './model'\n",
    "\n",
    "# 해당 폴더가 없다면 해당 폴더를 생성\n",
    "if not os.path.exists(MODEL_FOLDER) :\n",
    "    os.mkdir(MODEL_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f20ab567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장할 파일 명 설정\n",
    " #{epoch:04d} : 반복수를 4자리로 표시\n",
    "# {val_accuracy:.4f}:검증 정확도를 소수점 4째자리까지 표시\n",
    "#hdf5 파일형식\n",
    "modelpath = MODEL_FOLDER + './handnum-{epoch:04d}-{val_accuracy:4f}.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5cffef40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 베스트 모델을 찾아서 만들어둔 파일 명으로 저장\n",
    "# ModelCheckpoint(filepath = 파일 경로, monitor = 기준값,save_bast_only=True)\n",
    "#save_bast_only=True : 더 나은 결과값만 저장\n",
    "mc = ModelCheckpoint(filepath = modelpath,\n",
    "                    monitor = 'val_accuracy',\n",
    "                    save_best_only = True,\n",
    "                    verbose = 1) #verbose=1 진행결과를 보지 않겠다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c3c92da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EarlyStopping(monitor,patience = 기다리는 횟수)\n",
    "# patience = 20 : monitor 에 적은 기준에 따라 학습 결과가 더 나아지지 않더라도 \n",
    "#20번은 돌려보겠다.\n",
    "# patience가 있어야지만 조금씩 나아진 결과를 확인할 수 있다.\n",
    "#EarlyStopping 한 번 안좋아지면 멈춤\n",
    "es = EarlyStopping(monitor='val_accuracy',\n",
    "                  patience = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "067b24b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40199 samples, validate on 19801 samples\n",
      "Epoch 1/1000\n",
      "38900/40199 [============================>.] - ETA: 0s - loss: 0.0124 - accuracy: 0.9986\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.98899, saving model to ./model./handnum-0001-0.988990.hdf5\n",
      "40199/40199 [==============================] - 2s 51us/sample - loss: 0.0128 - accuracy: 0.9985 - val_loss: 0.0530 - val_accuracy: 0.9890\n",
      "Epoch 2/1000\n",
      "39200/40199 [============================>.] - ETA: 0s - loss: 0.0089 - accuracy: 0.9985\n",
      "Epoch 00002: val_accuracy improved from 0.98899 to 0.99020, saving model to ./model./handnum-0002-0.990202.hdf5\n",
      "40199/40199 [==============================] - 2s 52us/sample - loss: 0.0092 - accuracy: 0.9984 - val_loss: 0.0704 - val_accuracy: 0.9902\n",
      "Epoch 3/1000\n",
      "39500/40199 [============================>.] - ETA: 0s - loss: 0.0087 - accuracy: 0.9985\n",
      "Epoch 00003: val_accuracy improved from 0.99020 to 0.99187, saving model to ./model./handnum-0003-0.991869.hdf5\n",
      "40199/40199 [==============================] - 2s 55us/sample - loss: 0.0085 - accuracy: 0.9985 - val_loss: 0.0521 - val_accuracy: 0.9919\n",
      "Epoch 4/1000\n",
      "40150/40199 [============================>.] - ETA: 0s - loss: 0.0075 - accuracy: 0.9990\n",
      "Epoch 00004: val_accuracy did not improve from 0.99187\n",
      "40199/40199 [==============================] - 2s 50us/sample - loss: 0.0075 - accuracy: 0.9990 - val_loss: 0.0642 - val_accuracy: 0.9907\n",
      "Epoch 5/1000\n",
      "39900/40199 [============================>.] - ETA: 0s - loss: 0.0100 - accuracy: 0.9986\n",
      "Epoch 00005: val_accuracy improved from 0.99187 to 0.99227, saving model to ./model./handnum-0005-0.992273.hdf5\n",
      "40199/40199 [==============================] - 2s 49us/sample - loss: 0.0099 - accuracy: 0.9986 - val_loss: 0.0583 - val_accuracy: 0.9923\n",
      "Epoch 6/1000\n",
      "38700/40199 [===========================>..] - ETA: 0s - loss: 0.0034 - accuracy: 0.9995\n",
      "Epoch 00006: val_accuracy did not improve from 0.99227\n",
      "40199/40199 [==============================] - 2s 47us/sample - loss: 0.0035 - accuracy: 0.9994 - val_loss: 0.0956 - val_accuracy: 0.9878\n",
      "Epoch 7/1000\n",
      "39950/40199 [============================>.] - ETA: 0s - loss: 0.0064 - accuracy: 0.9988\n",
      "Epoch 00007: val_accuracy did not improve from 0.99227\n",
      "40199/40199 [==============================] - 2s 47us/sample - loss: 0.0069 - accuracy: 0.9988 - val_loss: 0.0709 - val_accuracy: 0.9907\n",
      "Epoch 8/1000\n",
      "38800/40199 [===========================>..] - ETA: 0s - loss: 0.0025 - accuracy: 0.9996\n",
      "Epoch 00008: val_accuracy improved from 0.99227 to 0.99303, saving model to ./model./handnum-0008-0.993031.hdf5\n",
      "40199/40199 [==============================] - 2s 48us/sample - loss: 0.0024 - accuracy: 0.9997 - val_loss: 0.0556 - val_accuracy: 0.9930\n",
      "Epoch 9/1000\n",
      "38650/40199 [===========================>..] - ETA: 0s - loss: 0.0017 - accuracy: 0.9997\n",
      "Epoch 00009: val_accuracy did not improve from 0.99303\n",
      "40199/40199 [==============================] - 2s 47us/sample - loss: 0.0017 - accuracy: 0.9997 - val_loss: 0.0742 - val_accuracy: 0.9909\n",
      "Epoch 10/1000\n",
      "38900/40199 [============================>.] - ETA: 0s - loss: 0.0092 - accuracy: 0.9985\n",
      "Epoch 00010: val_accuracy did not improve from 0.99303\n",
      "40199/40199 [==============================] - 2s 46us/sample - loss: 0.0092 - accuracy: 0.9985 - val_loss: 0.1175 - val_accuracy: 0.9865\n",
      "Epoch 11/1000\n",
      "38750/40199 [===========================>..] - ETA: 0s - loss: 0.0137 - accuracy: 0.9975\n",
      "Epoch 00011: val_accuracy did not improve from 0.99303\n",
      "40199/40199 [==============================] - 2s 47us/sample - loss: 0.0133 - accuracy: 0.9976 - val_loss: 0.0661 - val_accuracy: 0.9896\n",
      "Epoch 12/1000\n",
      "38850/40199 [===========================>..] - ETA: 0s - loss: 0.0068 - accuracy: 0.9991\n",
      "Epoch 00012: val_accuracy did not improve from 0.99303\n",
      "40199/40199 [==============================] - 2s 46us/sample - loss: 0.0066 - accuracy: 0.9992 - val_loss: 0.0608 - val_accuracy: 0.9906\n",
      "Epoch 13/1000\n",
      "38850/40199 [===========================>..] - ETA: 0s - loss: 0.0068 - accuracy: 0.9992\n",
      "Epoch 00013: val_accuracy did not improve from 0.99303\n",
      "40199/40199 [==============================] - 2s 47us/sample - loss: 0.0066 - accuracy: 0.9992 - val_loss: 0.0793 - val_accuracy: 0.9909\n",
      "Epoch 14/1000\n",
      "38700/40199 [===========================>..] - ETA: 0s - loss: 0.0025 - accuracy: 0.9996\n",
      "Epoch 00014: val_accuracy did not improve from 0.99303\n",
      "40199/40199 [==============================] - 2s 47us/sample - loss: 0.0024 - accuracy: 0.9996 - val_loss: 0.0817 - val_accuracy: 0.9919\n",
      "Epoch 15/1000\n",
      "38800/40199 [===========================>..] - ETA: 0s - loss: 0.0013 - accuracy: 0.9997\n",
      "Epoch 00015: val_accuracy did not improve from 0.99303\n",
      "40199/40199 [==============================] - 2s 47us/sample - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.0689 - val_accuracy: 0.9919\n",
      "Epoch 16/1000\n",
      "38900/40199 [============================>.] - ETA: 0s - loss: 0.0117 - accuracy: 0.9990\n",
      "Epoch 00016: val_accuracy did not improve from 0.99303\n",
      "40199/40199 [==============================] - 2s 47us/sample - loss: 0.0117 - accuracy: 0.9990 - val_loss: 0.1172 - val_accuracy: 0.9881\n",
      "Epoch 17/1000\n",
      "38800/40199 [===========================>..] - ETA: 0s - loss: 0.0087 - accuracy: 0.9988\n",
      "Epoch 00017: val_accuracy did not improve from 0.99303\n",
      "40199/40199 [==============================] - 2s 47us/sample - loss: 0.0089 - accuracy: 0.9987 - val_loss: 0.0759 - val_accuracy: 0.9891\n",
      "Epoch 18/1000\n",
      "39150/40199 [============================>.] - ETA: 0s - loss: 0.0049 - accuracy: 0.9992\n",
      "Epoch 00018: val_accuracy did not improve from 0.99303\n",
      "40199/40199 [==============================] - 2s 47us/sample - loss: 0.0049 - accuracy: 0.9991 - val_loss: 0.1161 - val_accuracy: 0.9892\n",
      "Epoch 19/1000\n",
      "39450/40199 [============================>.] - ETA: 0s - loss: 0.0066 - accuracy: 0.9992\n",
      "Epoch 00019: val_accuracy did not improve from 0.99303\n",
      "40199/40199 [==============================] - 2s 47us/sample - loss: 0.0065 - accuracy: 0.9992 - val_loss: 0.0886 - val_accuracy: 0.9912\n",
      "Epoch 20/1000\n",
      "39500/40199 [============================>.] - ETA: 0s - loss: 0.0252 - accuracy: 0.9980\n",
      "Epoch 00020: val_accuracy did not improve from 0.99303\n",
      "40199/40199 [==============================] - 2s 46us/sample - loss: 0.0248 - accuracy: 0.9981 - val_loss: 0.1021 - val_accuracy: 0.9892\n",
      "Epoch 21/1000\n",
      "39400/40199 [============================>.] - ETA: 0s - loss: 0.0073 - accuracy: 0.9986\n",
      "Epoch 00021: val_accuracy did not improve from 0.99303\n",
      "40199/40199 [==============================] - 2s 46us/sample - loss: 0.0074 - accuracy: 0.9986 - val_loss: 0.0900 - val_accuracy: 0.9895\n",
      "Epoch 22/1000\n",
      "39300/40199 [============================>.] - ETA: 0s - loss: 0.0084 - accuracy: 0.9987\n",
      "Epoch 00022: val_accuracy did not improve from 0.99303\n",
      "40199/40199 [==============================] - 2s 50us/sample - loss: 0.0086 - accuracy: 0.9987 - val_loss: 0.0938 - val_accuracy: 0.9906\n",
      "Epoch 23/1000\n",
      "39400/40199 [============================>.] - ETA: 0s - loss: 0.0157 - accuracy: 0.9992\n",
      "Epoch 00023: val_accuracy did not improve from 0.99303\n",
      "40199/40199 [==============================] - 2s 51us/sample - loss: 0.0154 - accuracy: 0.9993 - val_loss: 0.1021 - val_accuracy: 0.9896\n",
      "Epoch 24/1000\n",
      "39900/40199 [============================>.] - ETA: 0s - loss: 0.0024 - accuracy: 0.9996\n",
      "Epoch 00024: val_accuracy did not improve from 0.99303\n",
      "40199/40199 [==============================] - 2s 51us/sample - loss: 0.0024 - accuracy: 0.9997 - val_loss: 0.0743 - val_accuracy: 0.9914\n",
      "Epoch 25/1000\n",
      "39450/40199 [============================>.] - ETA: 0s - loss: 0.0052 - accuracy: 0.9994\n",
      "Epoch 00025: val_accuracy did not improve from 0.99303\n",
      "40199/40199 [==============================] - 2s 57us/sample - loss: 0.0053 - accuracy: 0.9994 - val_loss: 0.1018 - val_accuracy: 0.9895\n",
      "Epoch 26/1000\n",
      "38850/40199 [===========================>..] - ETA: 0s - loss: 0.0148 - accuracy: 0.9980\n",
      "Epoch 00026: val_accuracy did not improve from 0.99303\n",
      "40199/40199 [==============================] - 2s 51us/sample - loss: 0.0144 - accuracy: 0.9980 - val_loss: 0.0927 - val_accuracy: 0.9887\n",
      "Epoch 27/1000\n",
      "39700/40199 [============================>.] - ETA: 0s - loss: 0.0074 - accuracy: 0.9990\n",
      "Epoch 00027: val_accuracy did not improve from 0.99303\n",
      "40199/40199 [==============================] - 2s 54us/sample - loss: 0.0075 - accuracy: 0.9990 - val_loss: 0.1196 - val_accuracy: 0.9893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/1000\n",
      "40050/40199 [============================>.] - ETA: 0s - loss: 0.0070 - accuracy: 0.9990\n",
      "Epoch 00028: val_accuracy did not improve from 0.99303\n",
      "40199/40199 [==============================] - 2s 50us/sample - loss: 0.0070 - accuracy: 0.9990 - val_loss: 0.0750 - val_accuracy: 0.9911\n"
     ]
    }
   ],
   "source": [
    "#학습\n",
    "#validation_split=0.33: 전체 데이터중에서 33%를 검증데이터로 활용 평가\n",
    "history = model2.fit(X_train,y_train,epochs = 1000,batch_size = 50,\n",
    "                     validation_split=0.33,\n",
    "                    callbacks=[mc,es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c48010",
   "metadata": {},
   "outputs": [],
   "source": [
    "#저장할려면 모델 생성부터 다시 돌려야함"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
